---
title: "An Introduction to Bayesian VAR (BVAR) Models"
author: "Franz X. Mohr"
date: "2019-07-07"
tags:
  - r
  - bvar
  - var
  - bayes
  - bayesian-var
  - bvartools
  - gibbs-sampler
description: "An introduction into Bayesian VAR (BVAR) modelling and how to estimate it in R using Gibb sampling. The post also provides some experienced-based tips about important aspects that are usually not contained in textbooks."
---



<p>Bayesian methods have significantly gained in popularity during the last decades as computers have become more powerful and new software has been developed. Their flexibility and other advantageous features have made these methods also more popular in econometrics. This post gives a brief introduction to Bayesian VAR (BVAR) models and provides the code to set up and estimate a basic model with the <a href="https://cran.r-project.org/package=bvartools"><code>bvartools</code></a> package.</p>
<!--more-->
<div id="bvar-models" class="section level2">
<h2>BVAR models</h2>
<p>Bayesian VAR (BVAR) models have the same mathematical form as any other <a href="/timeseries/varintro">VAR model</a>, i.e.</p>
<p><span class="math display">\[ y_t = c + \sum_{l=i}^{p} A_i y_{t-i} + \epsilon_t,\]</span>
where <span class="math inline">\(y_t\)</span> is a <span class="math inline">\(K \times 1\)</span> vector of endogenous variables in period <span class="math inline">\(t\)</span>, <span class="math inline">\(A_i\)</span> is the cofficient matrix corresponding to the <span class="math inline">\(i\)</span>th lag of <span class="math inline">\(y_t\)</span>, <span class="math inline">\(c\)</span> is a constant deterministic term and <span class="math inline">\(\epsilon\)</span> is an error term with zero mean and variance-covariance <span class="math inline">\(\Sigma\)</span>.</p>
<p>The only difference between usual VAR models and BVAR models is the way parameter estimates are obtained and interpreted. VAR models are usually estimated by <a href="/methods/ols">OLS</a>, which is a simple and computationally fast estimator. By contrast, Bayesian estimators are slightly more complicated and more burdensome in terms of algebra and calculation power. The coefficients obtained by so-called <em>frequentist</em> estimators like OLS are interpreted based on the concept of the <a href="https://en.wikipedia.org/wiki/Sampling_distribution" target="_blank">sampling distribution</a>. In Bayesian inference, the coefficients are assumed to have their own distribution. A more detailed treatment of the difference between frequentist and Bayesian inference can be found in Kennedy (2008, ch. 14), which provides a short introduction to the Bayesian approach and a series of references for interested readers. Koop and Korobilis (2010) provide a very good introduction to Bayesian VAR estimators.</p>
<p>As already mentioned, Bayesian inference can be algebraically demanding. However, Bayesian estimators for linear VAR models can be implemented in a straightforward manner. A standard implementation is a so-called <strong>Gibbs sampler</strong>, which belongs to the family of Markov-Chain-Monte-Carlo (MCMC) methods. A detailed treatment of this method is beyond the scope of this post, but <a href="https://en.wikipedia.org/wiki/Gibbs_sampling">Wikipedia</a> might be a good start to become familiar with it. Personally, I like to think of the Gibbs sampler as throwing a bunch of random numbers at a model and see what sticks. The remainer of this text provides the code to set up and estimate a basic BVAR model with the <code>bvartools</code> package.</p>
</div>
<div id="model-and-data" class="section level2">
<h2>Model and data</h2>
<p>For this illustration the dataset E1 from Lütkepohl (2007) is used. It contains data on West German fixed investment, disposable income and consumption expenditures in billions of DM from 1960Q1 to 1982Q4. Following Lütkepohl (2007) the VAR model has two lags, i.e. <span class="math inline">\(p = 2\)</span> and only the first 73 observations are used for inference.</p>
<pre class="r"><code>library(bvartools)

data(&quot;e1&quot;) # Load the data
e1 &lt;- diff(log(e1)) # Calculate first-log-differences</code></pre>
<p>Basically, it would be possible to proceed without any further transformation of the data. However, it is good practise to multiply log-differenced data by 100 so that, for example, the value 1% is indicated by 1 and not by 0.01.</p>
<pre class="r"><code>e1 &lt;- e1 * 100 # Rescale data

plot(e1) # Plot the series</code></pre>
<p><img src="/timeseries/bvar_files/figure-html/unnamed-chunk-1-1.png" width="432" style="display: block; margin: auto;" /></p>
<p>To assist with the set-up of the model the <code>gen_var</code> function produces the inputs <code>y</code> and <code>x</code> for the estimator, where <code>y</code> is a matrix of dependent variables and <code>x</code> is the matrix of regressors for the model</p>
<p><span class="math display">\[y_t = A x_t + u_t,\]</span>
with <span class="math inline">\(u_t \sim N(0, \Sigma)\)</span>. This is a more compact form of the model above, where the lags of the endogenous variables and the constant are already included in <span class="math inline">\(x_t\)</span>.</p>
<pre class="r"><code>data &lt;- gen_var(e1, p = 2, deterministic = &quot;const&quot;)

y &lt;- data$Y[, 1:73]
x &lt;- data$Z[, 1:73]</code></pre>
</div>
<div id="estimation" class="section level2">
<h2>Estimation</h2>
<div id="frequentist-estimator" class="section level3">
<h3>Frequentist estimator</h3>
<p>We calculate frequentist VAR estimates using the standard formula <span class="math inline">\(y x&#39; (x x&#39;)^{-1}\)</span> to obtain a benchmark for the Bayesian estimator. The parameters are obtained by OLS:</p>
<pre class="r"><code>A_freq &lt;- tcrossprod(y, x) %*% solve(tcrossprod(x)) # Calculate estimates
round(A_freq, 3) # Round estimates and print</code></pre>
<pre><code>##        invest.1 income.1 cons.1 invest.2 income.2 cons.2  const
## invest   -0.320    0.146  0.961   -0.161    0.115  0.934 -1.672
## income    0.044   -0.153  0.289    0.050    0.019 -0.010  1.577
## cons     -0.002    0.225 -0.264    0.034    0.355 -0.022  1.293</code></pre>
<p>And <span class="math inline">\(\Sigma\)</span> is calculated by</p>
<pre class="r"><code>u_freq &lt;- y - A_freq %*% x
u_sigma_freq &lt;- tcrossprod(u_freq) / (ncol(y) - nrow(x))
round(u_sigma_freq, 2)</code></pre>
<pre><code>##        invest income cons
## invest  21.30   0.72 1.23
## income   0.72   1.37 0.61
## cons     1.23   0.61 0.89</code></pre>
<p>These are virtually the same values as in Lütkepohl (2007, Ch. 3). The only differences stem from the re-scaling of the data above, which results in proportionally higher values for the <code>const</code> variable and does not require us to multiply the covariance matrix by <span class="math inline">\(10^4\)</span>.</p>
</div>
<div id="bayesian-estimator" class="section level3">
<h3>Bayesian estimator</h3>
<p>The following code is a Gibbs sampler for a simple VAR model with non-informative priors. First, we define some variables, which help in the set-up of the sampler:</p>
<pre class="r"><code># Reset random number generator for reproducibility
set.seed(1234567)

iter &lt;- 30000 # Number of iterations of the Gibbs sampler
burnin &lt;- 15000 # Number of burn-in draws
store &lt;- iter - burnin

tt &lt;- ncol(y) # Number of observations
k &lt;- nrow(y) # Number of endogenous variables
m &lt;- k * nrow(x) # Number of estimated coefficients</code></pre>
<p>Next, we set the priors. The prior means of the coefficient vector <span class="math inline">\(a = vec(A)\)</span> are set to <span class="math inline">\(0\)</span> and the diagonal elements of the corresponding covariance matrix <span class="math inline">\(V\)</span> are set to <span class="math inline">\(1\)</span>, except for coefficients corresponding to intercept terms, which are set to <span class="math inline">\(10\)</span>. The prior degrees of freedom of the error term are set to <span class="math inline">\(6\)</span> and the diagonal elements of the scale matrix to <span class="math inline">\(1\)</span>.</p>
<p><em>Note that the choice of the prior variances for coefficients, which correspond to intercept terms, can be motivated by the values of the analysed time series. For example, if a stationary series seems to move around the value <span class="math inline">\(5\)</span>, this could be taken into account by setting the prior mean of the respective coefficients to <span class="math inline">\(5\)</span> with a small prior variance around it. If the researcher still prefers to set the mean to <span class="math inline">\(0\)</span>, it should be ensured that the prior variance is large enough so that the value <span class="math inline">\(5\)</span> is captured by the prior distribution.</em></p>
<p><em>Note that the choice of the prior variances of the errors can be highly influential if the scale of the errors is not taken into account appropriately. For example, if the dependent variable does exceed values between <span class="math inline">\(-0.1\)</span> and <span class="math inline">\(0.1\)</span>, a prior of <span class="math inline">\(1\)</span> would be too high and could lead to useless results.</em></p>
<pre class="r"><code># Set priors
a_mu_prior &lt;- matrix(0, m) # Vector of prior parameter means
a_v_i_prior &lt;- diag(1, m) # Inverse of the prior covariance matrix

u_sigma_df_prior &lt;- 6 # Prior degrees of freedom
u_sigma_scale_prior &lt;- diag(1, k) # Prior covariance matrix
u_sigma_df_post &lt;- tt + u_sigma_df_prior # Posterior degrees of freedom</code></pre>
<p><em>Note that we could also use uninformative priors, where all elements of the inverse prior covariance matrix <span class="math inline">\(V^{-1}\)</span> are set to zero and the prior degrees of freedom and the elements of the scale matrix are set to 0 as well. Such a specification should lead to posterior draws, which mimic the results of a frequentist OLS estimator.</em></p>
<p>Then we obtain some starting values. It might be a good idea to start with the OLS estimates of the model.</p>
<pre class="r"><code># Initial values
u_sigma_i &lt;- solve(u_sigma_freq)</code></pre>
<p>Next, create object, in which the posterior draws are saved for later.</p>
<pre class="r"><code># Data containers for posterior draws
draws_a &lt;- matrix(NA, m, store)
draws_sigma &lt;- matrix(NA, k * k, store)</code></pre>
<p>Finally run the Gibbs sampler.</p>
<pre class="r"><code># Start Gibbs sampler
for (draw in 1:iter) {
  # Draw conditional mean parameters
  a &lt;- post_normal(y, x, u_sigma_i, a_mu_prior, a_v_i_prior)

  # Draw variance-covariance matrix
  u &lt;- y - matrix(a, k) %*% x # Obtain residuals
  u_sigma_scale_post &lt;- solve(u_sigma_scale_prior + tcrossprod(u))
  u_sigma_i &lt;- matrix(rWishart(1, u_sigma_df_post, u_sigma_scale_post)[,, 1], k)
  u_sigma &lt;- solve(u_sigma_i) # Invert Sigma_i to obtain Sigma

  # Store draws
  if (draw &gt; burnin) {
    draws_a[, draw - burnin] &lt;- a
    draws_sigma[, draw - burnin] &lt;- u_sigma
  }
}</code></pre>
<p>After the Gibbs sampler has finished, point estimates for the coefficient matrix can be obtained as, e.g., the mean of the posterior draws:</p>
<pre class="r"><code>A &lt;- rowMeans(draws_a) # Obtain means for every row
A &lt;- matrix(A, k) # Transform mean vector into a matrix
A &lt;- round(A, 3) # Round values
dimnames(A) &lt;- list(dimnames(y)[[1]], dimnames(x)[[1]]) # Rename matrix dimensions

A # Print</code></pre>
<pre><code>##        invest.1 income.1 cons.1 invest.2 income.2 cons.2  const
## invest   -0.284    0.200  0.573   -0.141    0.170  0.540 -0.353
## income    0.041   -0.132  0.327    0.048    0.036  0.035  1.307
## cons     -0.003    0.237 -0.244    0.033    0.365  0.000  1.145</code></pre>
<p>Point estimates for the covariance matrix can also be obtained by calculating the means of the posterior draws.</p>
<pre class="r"><code>Sigma &lt;- rowMeans(draws_sigma) # Obtain means for every row
Sigma &lt;- matrix(Sigma, k) # Transform mean vector into a matrix
Sigma &lt;- round(Sigma, 2) # Round values
dimnames(Sigma) &lt;- list(dimnames(y)[[1]], dimnames(y)[[1]]) # Rename matrix dimensions

Sigma # Print</code></pre>
<pre><code>##        invest income cons
## invest  20.45   0.64 1.15
## income   0.64   1.35 0.59
## cons     1.15   0.59 0.88</code></pre>
<p>The means of the coefficient draws are relatively close to the results of the frequentist estimatior. <em>However, note that the frequentist estimator suggests coefficients, which are close to <span class="math inline">\(1\)</span> for the relationship between investment and consumption. By contrast, the Bayesian estimator implies different point estimates, which might be a result of the rather close prior variance of <span class="math inline">\(1\)</span> for those parameters. As mentioned above, using a non-informative prior will lead to results that are closer to the OLS estimates.</em></p>
</div>
</div>
<div id="bvar-objects" class="section level2">
<h2><code>bvar</code> objects</h2>
<p>The <code>bvar</code> function can be used to collect relevant output of the Gibbs sampler into a standardised object, which can be used by further functions such as <code>predict</code> to obtain forecasts or <code>irf</code> for <a href="/timeseries/irf">impulse respons analysis</a>.</p>
<pre class="r"><code>bvar_est &lt;- bvar(y = y, x = x, A = draws_a[1:18,],
                 C = draws_a[19:21, ], Sigma = draws_sigma)</code></pre>
<p>Posterior draws can be thinned with the function <code>thin</code>:</p>
<pre class="r"><code>bvar_est &lt;- thin(bvar_est, thin = 15)</code></pre>
</div>
<div id="forecasts" class="section level2">
<h2>Forecasts</h2>
<p>Forecasts with credible bands can be obtained with the function <code>predict</code>. If the model contains deterministic terms, new values can be provided in the argument <code>new_D</code>. If no values are provided, the function sets them to zero. The number of rows of <code>new_D</code> must be the same as the argument <code>n.ahead</code>.</p>
<pre class="r"><code>bvar_pred &lt;- predict(bvar_est, n.ahead = 10, new_D = rep(1, 10))

plot(bvar_pred)</code></pre>
<p><img src="/timeseries/bvar_files/figure-html/forecasts-1.png" width="528" /></p>
</div>
<div id="impulse-response-analysis" class="section level2">
<h2>Impulse response analysis</h2>
<p>Currently, <code>bvartools</code> supports forecast error, orthogonalised, and generalised impulse response functions.</p>
<div id="forecast-error-impulse-response" class="section level3">
<h3>Forecast error impulse response</h3>
<pre class="r"><code>FEIR &lt;- irf(bvar_est, impulse = &quot;income&quot;, response = &quot;cons&quot;, n.ahead = 8)

plot(FEIR, main = &quot;Forecast Error Impulse Response&quot;, xlab = &quot;Period&quot;, ylab = &quot;Response&quot;)</code></pre>
<p><img src="/timeseries/bvar_files/figure-html/feir-1.png" width="528" /></p>
</div>
<div id="orthogonalised-impulse-response" class="section level3">
<h3>Orthogonalised impulse response</h3>
<pre class="r"><code>OIR &lt;- irf(bvar_est, impulse = &quot;income&quot;, response = &quot;cons&quot;, n.ahead = 8, type = &quot;oir&quot;)

plot(OIR, main = &quot;Orthogonalised Impulse Response&quot;, xlab = &quot;Period&quot;, ylab = &quot;Response&quot;)</code></pre>
<p><img src="/timeseries/bvar_files/figure-html/oir-1.png" width="528" /></p>
</div>
<div id="generalised-impulse-response" class="section level3">
<h3>Generalised impulse response</h3>
<pre class="r"><code>GIR &lt;- irf(bvar_est, impulse = &quot;income&quot;, response = &quot;cons&quot;, n.ahead = 8, type = &quot;gir&quot;)

plot(GIR, main = &quot;Generalised Impulse Response&quot;, xlab = &quot;Period&quot;, ylab = &quot;Response&quot;)</code></pre>
<p><img src="/timeseries/bvar_files/figure-html/gir-1.png" width="528" /></p>
</div>
</div>
<div id="forecast-error-variance-decomposition" class="section level2">
<h2>Forecast error variance decomposition</h2>
<p>Default forecast error variance decomposition (FEVD) is based on orthogonalised impulse responses (OIR).</p>
<pre class="r"><code>bvar_fevd_oir &lt;- fevd(bvar_est, response = &quot;cons&quot;)

plot(bvar_fevd_oir, main = &quot;OIR-based FEVD of consumption&quot;)</code></pre>
<p><img src="/timeseries/bvar_files/figure-html/fevd-oir-1.png" width="528" /></p>
<p>It is also possible to calculate FEVDs, which are based on generalised impulse responses (GIR). Note that these do not automatically add up to unity.</p>
<pre class="r"><code>bvar_fevd_gir &lt;- fevd(bvar_est, response = &quot;cons&quot;, type = &quot;gir&quot;)

plot(bvar_fevd_gir, main = &quot;GIR-based FEVD of consumption&quot;)</code></pre>
<p><img src="/timeseries/bvar_files/figure-html/fevd-gir-1.png" width="528" /></p>
</div>
<div id="references" class="section level2">
<h2>References</h2>
<!-- Eddelbuettel, D., & Sanderson C. (2014). RcppArmadillo: Accelerating R with high-performance C++ linear algebra. *Computational Statistics and Data Analysis, 71*, 1054-1063. <https://doi.org/10.1016/j.csda.2013.02.005> -->
<p>Koop, G., &amp; Korobilis, D. (2010). Bayesian multivariate time series methods for empirical macroeconomics. <em>Foundations and trends in econometrics, 3</em>(4), 267-358. <a href="https://dx.doi.org/10.1561/0800000013" class="uri">https://dx.doi.org/10.1561/0800000013</a></p>
<p>Koop, G., Pesaran, M. H., &amp; Potter, S.M. (1996). Impulse response analysis in nonlinear multivariate models. <em>Journal of Econometrics 74</em>(1), 119-147. <a href="https://doi.org/10.1016/0304-4076(95)01753-4" class="uri">https://doi.org/10.1016/0304-4076(95)01753-4</a></p>
<p>Lütkepohl, H. (2007). <em>New introduction to multiple time series analysis</em> (2nd ed.). Berlin: Springer.</p>
<p>Kennedy, P. (2008). <em>A guide to econometrics</em> (6th ed.) Malden, MA: Blackwell.</p>
<p>Pesaran, H. H., &amp; Shin, Y. (1998). Generalized impulse response analysis in linear multivariate models. <em>Economics Letters, 58</em>(1), 17-29. <a href="https://doi.org/10.1016/S0165-1765(97)00214-0" class="uri">https://doi.org/10.1016/S0165-1765(97)00214-0</a></p>
<!-- Plummer, M., Best, N., Cowles, K., & Vines, K. (2006). CODA: Convergence Diagnosis and Output Analysis for MCMC. *R News, 6*(1), 7-11. [https://www.r-project.org/doc/Rnews/Rnews_2006-1.pdf](https://www.r-project.org/doc/Rnews/Rnews_2006-1.pdf) -->
<!-- Sanderson, C., & Curtin, R. (2016). Armadillo: a template-based C++ library for linear algebra. *Journal of Open Source Software, 1*(2), 26. <https://doi.org/10.21105/joss.00026> -->
<!-- [^cpp]: `RcppArmadillo` is the `Rcpp` bridge to the open source 'Armadillo' -->
<!-- library of Sanderson and Curtin (2016). -->
</div>
