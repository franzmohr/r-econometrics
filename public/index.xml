<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>r-econometrics</title>
    <link>https://www.r-econometrics.com/</link>
    <description>Recent content on r-econometrics</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 11 Jan 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://www.r-econometrics.com/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>bvartools</title>
      <link>https://www.r-econometrics.com/bvartools/</link>
      <pubDate>Fri, 30 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/bvartools/</guid>
      <description>&lt;p&gt;This section should help you to&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.r-econometrics.com/timeseries/bvar&#34;&gt;estimate simple Bayesian VAR models&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>r-econometrics</title>
      <link>https://www.r-econometrics.com/index_dummy/</link>
      <pubDate>Thu, 15 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/index_dummy/</guid>
      <description>&lt;p&gt;You want to learn the basics of the R programming language and how to use the software for econometric analyses? Great! This site could be useful for you. It is about learning how to use the free statistical software R for basic econometric applications and shall provide an intuition of the basic structure of the program and statistical functions, which are needed to pass introductory or intermediate courses in econometrics. The focus is less on the math behind the statistical methods and more on their application, so that newcomers become familiar with the language quickly.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bayesian Inference of Structural Vector Autoregressions (SVAR) with the `bvartools` package</title>
      <link>https://www.r-econometrics.com/timeseries/bayes-svar-intro/</link>
      <pubDate>Mon, 11 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/timeseries/bayes-svar-intro/</guid>
      <description>&lt;p&gt;The &lt;a href=&#34;https://cran.r-project.org/package=bvartools&#34; target=&#34;_blank&#34;&gt;bvartools&lt;/a&gt; allows to perform Bayesian inference of &lt;a href=&#34;https://www.r-econometrics.com/timeseries/varintro&#34; target=&#34;_blank&#34;&gt;Vector autoregressive (VAR) models&lt;/a&gt;, including &lt;a href=&#34;https://www.r-econometrics.com/timeseries/svarintro&#34; target=&#34;_blank&#34;&gt;structural VARs&lt;/a&gt;. This post guides through the Bayesian inference of SVAR models in R using the &lt;code&gt;bvartools&lt;/code&gt; package.&lt;/p&gt;&#xA;&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Data&lt;/h2&gt;&#xA;&lt;p&gt;For this illustration we generate an artificial data set with three endogenous variables, which follows the data generating process&lt;/p&gt;&#xA;&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_t = A_1 y_{t - 1} + B \epsilon_t,\]&lt;/span&gt;&lt;/p&gt;&#xA;&lt;p&gt;where&lt;/p&gt;&#xA;&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[&#xA;A_1 = \begin{bmatrix} 0.3 &amp;amp; 0.12 &amp;amp; 0.69 \\ 0 &amp;amp; 0.3 &amp;amp; 0.48 \\ 0.24 &amp;amp; 0.24 &amp;amp; 0.3 \end{bmatrix} \text{, }&#xA;B = \begin{bmatrix} 1 &amp;amp; 0 &amp;amp; 0 \\ -0.14 &amp;amp; 1 &amp;amp; 0 \\ -0.06 &amp;amp; 0.39 &amp;amp; 1 \end{bmatrix} \text{ and } \epsilon_t \sim N(0, I_3).&#xA;\]&lt;/span&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Decomposing Inflation for EA Countries</title>
      <link>https://www.r-econometrics.com/2022/04/03/decomposing-inflation-for-ea-countries/</link>
      <pubDate>Sun, 03 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/2022/04/03/decomposing-inflation-for-ea-countries/</guid>
      <description>&lt;p&gt;As a result of supply chain disruptions due to the Covid-19 pandemic and the recent war in the Ukraine inflation has reached unusually high levels during the past months.&#xA;A first approach to analyse the evolution of inflation over time is to look at its main components: energy, food, services and industrial goods. To do this, I use data from Eurostat, which can be easily loaded into R using the &lt;code&gt;eurostat&lt;/code&gt; package for countries of the European Union.&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Introduction to Dynamic Factor Models</title>
      <link>https://www.r-econometrics.com/timeseries/dynamicfactorintro/</link>
      <pubDate>Sun, 25 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/timeseries/dynamicfactorintro/</guid>
      <description>&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;For some macroeconomic applications it might be interesting to see whether a set of obserable variables depends on common drivers. The estimation of such common factors can be done using so-called &lt;em&gt;factor analytical models&lt;/em&gt;, which have the form&lt;/p&gt;&#xA;&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[x_t = \lambda f_t + u_t,\]&lt;/span&gt;&lt;/p&gt;&#xA;&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(x_t\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;-dimensional vector of observable variables, &lt;span class=&#34;math inline&#34;&gt;\(f_t\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(N \times 1\)&lt;/span&gt; vector of unobserved factors, &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(M \times N\)&lt;/span&gt; matrix of factor loadings and &lt;span class=&#34;math inline&#34;&gt;\(u_t\)&lt;/span&gt; is an error term.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Short Notes on Bayesian Inference of Vector Autoregressive Models</title>
      <link>https://www.r-econometrics.com/timeseries/bayesnotes/</link>
      <pubDate>Sun, 16 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/timeseries/bayesnotes/</guid>
      <description>&lt;p&gt;During the past years I realised that econometric analyis can be understood as a craft. You learn your basics at school from more or less motivated/talented professors and then you are sent out into wild, where you are confronted with real life challenges that differ from the stylised exmples you have become used to during your studies. This comes with a bunch new insights that I want to document on this page. It should become a collection of notes on Bayesian VAR modelling that have become imporant to me over the last years.&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Introduction to Structural Vector Autoregression (SVAR)</title>
      <link>https://www.r-econometrics.com/timeseries/svarintro/</link>
      <pubDate>Thu, 13 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/timeseries/svarintro/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.r-econometrics.com/timeseries/varintro&#34; target=&#34;_blank&#34;&gt;Vector autoregressive (VAR) models&lt;/a&gt; constitute a rather general approach to modelling multivariate time series. A critical drawback of those models in their standard form is their missing ability to describe contemporaneous relationships between the analysed variables. This becomes a central issue in the &lt;a href=&#34;https://www.r-econometrics.com/timeseries/irf&#34; target=&#34;_blank&#34;&gt;impulse response analysis&lt;/a&gt; for such models, where it is important to know the contemporaneous effects of a shock to the economy. Usually, researchers address this by using orthogonal impulse responses, where the correlation between the errors is obtained from the (lower) Cholesky decomposition of the error covariance matrix. This requires them to arrange the variables of the model in a suitable order. An alternative to this approach is to use so-called &lt;em&gt;structural vector autoregressive (SVAR)&lt;/em&gt; models, where the relationship between contemporaneous variables is modelled more directly. This post provides an introduction to the concept of SVAR models and how they can be estimated in R.&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Introduction to Stationarity and Unit Roots in Time Series Analysis</title>
      <link>https://www.r-econometrics.com/timeseries/stationarity/</link>
      <pubDate>Sun, 09 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/timeseries/stationarity/</guid>
      <description>&lt;div id=&#34;concepts&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Concepts&lt;/h2&gt;&#xA;&lt;p&gt;Basically &lt;strong&gt;stationarity&lt;/strong&gt; means that a time series has a constant mean and constant variance over time. Althouth not particularly imporant for the estimation of parameters of econometric models these features are essential for the calculation of reliable test statistics and, hence, can have a significant impact on model selection.&lt;/p&gt;&#xA;&lt;p&gt;To illustrate this concept, let’s look at quarterly data on disposable income in billion DM from 1960 to 1982, which is data set E1 from Luetkepohl (2007).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Producing a labour market dashboard using Eurostat data</title>
      <link>https://www.r-econometrics.com/2020/04/19/producing-a-labour-market-dashboard-using-eurostat-data/</link>
      <pubDate>Sun, 19 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/2020/04/19/producing-a-labour-market-dashboard-using-eurostat-data/</guid>
      <description></description>
    </item>
    <item>
      <title>An Introduction to Impulse Response Analysis of VAR Models</title>
      <link>https://www.r-econometrics.com/timeseries/irf/</link>
      <pubDate>Sat, 21 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/timeseries/irf/</guid>
      <description>&lt;p&gt;Impulse response analysis is an important step in econometric analyes, which employ &lt;a href=&#34;https://www.r-econometrics.com/timeseries/varintro&#34; target=&#34;_blank&#34;&gt;vector autoregressive models&lt;/a&gt;. Their main purpose is to describe the evolution of a model’s variables in reaction to a shock in one or more variables. This feature allows to trace the transmission of a single shock within an otherwise noisy system of equations and, thus, makes them very useful tools in the assessment of economic policies. This post provides an introduction to the concept and interpretation of impulse response functions as they are commonly used in the VAR literature and provides code for their calculation in R.&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Introduction to Network Analysis in R</title>
      <link>https://www.r-econometrics.com/2020/03/01/an-introduction-to-network-analysis-in-r/</link>
      <pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/2020/03/01/an-introduction-to-network-analysis-in-r/</guid>
      <description>&lt;p&gt;With the increasing availability of granular data on the relationships between individual entities - such as persons (social media), countries (internatinal trade) and financial institutions (supervisory reporting) - network analysis offers many possibilities to extract useful information from such data. This post provides an introduction to network analysis in R using the powerful &lt;code&gt;igraph&lt;/code&gt; package for the calculation of metrics and &lt;code&gt;ggraph&lt;/code&gt; for visualisation. It marks the beginning of a more comprehensive treatment of &lt;a href=&#34;https://www.r-econometrics.com/networksintro/&#34; target=&#34;_blank&#34;&gt;network analysis on r-econometrics&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Basics of the igraph Package</title>
      <link>https://www.r-econometrics.com/networks/igraph/</link>
      <pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/networks/igraph/</guid>
      <description>&lt;p&gt;There are multiple packages for the analysis of networks in R. This page concentrates on the &lt;code&gt;igraph&lt;/code&gt; package, which allows for a broad range of applications. But before we get into it in more detail, it is useful to know that there are two possible ways to represent the &lt;em&gt;edges&lt;/em&gt;, i.e. the connections, of a network:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Adjacency matrix&lt;/strong&gt;: This is a square matrix, where each row and column corresponds to an entity. If two entities are conencted, the respective field in the matrix takes the value one and zero otherwise.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;A list of connections&lt;/strong&gt;: In its most simple form this is a list, where each edge of a network is represented by a row with one entity in the first column and the other in the second. For the purpose of this post this is our preferred representation.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div id=&#34;create-an-artificial-graph&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Create an artificial graph&lt;/h2&gt;&#xA;&lt;p&gt;We can illustrate these two representations by looking at an artificial network. Such a network could be generated with certain functions of the &lt;code&gt;igraph&lt;/code&gt; package. However, the following code only uses base functionalities of R. It results in a data frame with the names of the connected entities in the first and second row. The third row contains a random indicator for the strength of the connection. It is based on the square of a value from a standard normal distribution. To reduce the number of resulting edges, only values above a certain threshold are kept. Also, the code excludes the connections a node has with itself.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Network Analysis in R</title>
      <link>https://www.r-econometrics.com/networksintro/</link>
      <pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/networksintro/</guid>
      <description>&lt;p&gt;With the increasing availability of granular data on the relationships between individual entities - such as persons (social media), countries (internatinal trade) and financial institutions (supervisory reporting) - network analysis offers many possibilities to extract useful information from such data. This section provides brief introductions to the analysis of network data in R.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.r-econometrics.com/networks/igraph&#34;&gt;Basics of the igraph package&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.r-econometrics.com/networks/network-summary&#34;&gt;Summary statistics with the igraph&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.r-econometrics.com/networks/network-visual&#34;&gt;Network visualisation with ggraph&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Network Summary Statistics</title>
      <link>https://www.r-econometrics.com/networks/network-summary/</link>
      <pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/networks/network-summary/</guid>
      <description>&lt;p&gt;If a network is small, it can be easily summarised by its graph or a figure. But once a network reaches a certain size, it becomes more meaningful to use more formal summary statistics in order to describe its features. This post covers some basic network summary statistics as presented in Jackson (2008). The metrics are based on the concept of &lt;em&gt;centrality&lt;/em&gt;, which describes the importance of a node in a given network of nodes.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Network Visualisation in R</title>
      <link>https://www.r-econometrics.com/networks/network-visual/</link>
      <pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/networks/network-visual/</guid>
      <description>&lt;p&gt;Beside the calculation of summarising network metrics, the visualisation of a graph can also be a very informative step in network analysis. Since visualisations in R usually involve the &lt;code&gt;ggplot2&lt;/code&gt; package, I focus on the &lt;code&gt;ggraph&lt;/code&gt; package, which is based on the &lt;code&gt;ggplot2&lt;/code&gt; architecture. For illustration I use the artificial data set from my &lt;a href=&#34;https://www.r-econometrics.com/2020/03/01/an-introduction-to-network-analysis-in-r/&#34; target=&#34;_blank&#34;&gt;post on network analysis&lt;/a&gt;, which is an &lt;code&gt;igraph&lt;/code&gt; object names &lt;code&gt;graph_df&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;p&gt;When using &lt;code&gt;ggplot2&lt;/code&gt; the main challenge in the visualisation of networks is to find suitable x- and y-coordinates for the nodes of a graph. Fortunately, there are some packages out there, which were developed for this purpose. For example, &lt;code&gt;ggraph&lt;/code&gt; and &lt;code&gt;ggnetwork&lt;/code&gt; take an &lt;code&gt;igraph&lt;/code&gt; object and produce tables with suitable coordianates. These coordinates are usually obtained by using special algorithms such as the ones proposed by Fruchterman and Reingold (1991) or Kamada and Kawai (1989). The latter is applied in the code below.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Machine Learning</title>
      <link>https://www.r-econometrics.com/_mlintro/</link>
      <pubDate>Mon, 03 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/_mlintro/</guid>
      <description>&lt;p&gt;With the increasing availability of computational capabilities and granular data, machine learning has become more important.&lt;/p&gt;&#xA;&lt;div id=&#34;classification&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Classification&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.r-econometrics.com/ml/neuralnetwork&#34;&gt;Neural networks&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.r-econometrics.com/ml/randomforest&#34;&gt;Random forests&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.r-econometrics.com/ml/svm&#34;&gt;Support vector machines (SVM)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Chapter 11: Monte Carlo Integration</title>
      <link>https://www.r-econometrics.com/reproduction/bayesmethods/bayesmethods11/</link>
      <pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/bayesmethods/bayesmethods11/</guid>
      <description>&lt;div id=&#34;exercise-11.2-drawing-frmm-standard-distributions&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Exercise 11.2: Drawing frmm standard distributions&lt;/h2&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Sample size&#xA;n1 &amp;lt;- 10L&#xA;n2 &amp;lt;- 100L&#xA;n3 &amp;lt;- 100000L&#xA;# We use integers as indicated by the &amp;quot;L&amp;quot; at the end of the number.&#xA;# This only makes the results look nicer&#xA;&#xA;# Reset random number generator for reproducibilty&#xA;set.seed(123456)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;div id=&#34;uniform&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Uniform&lt;/h3&gt;&#xA;&lt;p&gt;The standard specification of R’s random number generator (RNG) &lt;code&gt;runif&lt;/code&gt; is &lt;code&gt;min = 0&lt;/code&gt; and &lt;code&gt;max = 1&lt;/code&gt;, which is exactly what we need. So we only have to specify the number of draws.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chapter 20: Multivariate Time Series Methods</title>
      <link>https://www.r-econometrics.com/reproduction/bayesmethods/bayesmethods20/</link>
      <pubDate>Mon, 09 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/bayesmethods/bayesmethods20/</guid>
      <description>&lt;p&gt;Load required packages&lt;/p&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(bvartools)&#xA;library(dplyr)&#xA;library(ggplot2)&#xA;library(spam)&#xA;library(tidyr)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Data&lt;/h2&gt;&#xA;&lt;p&gt;US macro data until 2007Q4&lt;/p&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Specify URL&#xA;url &amp;lt;- &amp;quot;https://web.ics.purdue.edu/~jltobias/second_edition/Chapter20/code_for_exercise_1/US_macrodata.csv&amp;quot;&#xA;# Load data&#xA;us_macro_2007 &amp;lt;- read.csv(url, col.names = c(&amp;quot;date&amp;quot;, &amp;quot;Dp&amp;quot;, &amp;quot;u&amp;quot;, &amp;quot;r&amp;quot;))&#xA;# Omit NA values&#xA;us_macro_2007 &amp;lt;- na.omit(us_macro_2007)&#xA;# Transform into time-series object&#xA;us_macro_2007 &amp;lt;- ts(us_macro_2007[, -1], start = c(1959, 2), frequency = 4)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div id=&#34;exercise-20.1&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Exercise 20.1&lt;/h2&gt;&#xA;&lt;p&gt;Prepare the data&lt;/p&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;temp &amp;lt;- gen_var(us_macro_2007, p = 2, deterministic = &amp;quot;const&amp;quot;)&#xA;y &amp;lt;- temp$Y&#xA;x &amp;lt;- temp$Z&#xA;&#xA;k &amp;lt;- NROW(y)&#xA;tt &amp;lt;- ncol(y)&#xA;z &amp;lt;- kronecker(t(x), diag(1, k))&#xA;m &amp;lt;- ncol(z)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Specify the priors&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chapter 18: State Space and Unobserved Components Models</title>
      <link>https://www.r-econometrics.com/reproduction/bayesmethods/bayesmethods18/</link>
      <pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/bayesmethods/bayesmethods18/</guid>
      <description>&lt;div id=&#34;exercise-18.1-the-local-level-model&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Exercise 18.1: The local level model&lt;/h2&gt;&#xA;&lt;div id=&#34;data-us-pce-inflation-until-2015q4&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Data: US PCE inflation until 2015Q4&lt;/h3&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Specify URL&#xA;url &amp;lt;- &amp;quot;https://web.ics.purdue.edu/~jltobias/second_edition/Chapter18/code_for_exercise_1/USPCE_2015Q4.csv&amp;quot;&#xA;&#xA;# Load data&#xA;pce &amp;lt;- read.csv(url, header = FALSE, col.names = &amp;quot;pci&amp;quot;)&#xA;&#xA;# Log growth rates&#xA;pce &amp;lt;- diff(ts(log(pce), start = 1959, frequency = 4))&#xA;&#xA;# Rescale&#xA;y &amp;lt;- matrix(pce * 100 * 4, 1)&#xA;tt &amp;lt;- ncol(y) # T&#xA;z &amp;lt;- diag(1, tt) # Data matrix&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div id=&#34;estimation&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Estimation&lt;/h3&gt;&#xA;&lt;p&gt;Prior&lt;/p&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a0 &amp;lt;- 5&#xA;b0 &amp;lt;- 100&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Initial values&lt;/p&gt;</description>
    </item>
    <item>
      <title>Standard Test Statistics for OLS Models in R</title>
      <link>https://www.r-econometrics.com/methods/teststats/</link>
      <pubDate>Mon, 25 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/methods/teststats/</guid>
      <description>&lt;p&gt;Model testing belongs to the main tasks of any econometric analysis. This post gives an overview of tests, which should be applied to OLS regressions, and illustrates how to calculate them in R. The focus of the post is rather on the calcuation of the tests. For a treatment of mathematical details, please, consult a standard textbook. This list of statistical tests is necessarily incomplete. However, if you have a strong opinion that a specific test is missing, feel free to leave a comment below.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to dplyr</title>
      <link>https://www.r-econometrics.com/rbasics/dplyrintro/</link>
      <pubDate>Mon, 07 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/rbasics/dplyrintro/</guid>
      <description>&lt;p&gt;The cleaning and transformation of data belong to the most time consuming parts of any economic analysis. Many graphical or statistical functions in R require specifically formatted data to work properly. Although the standard functions of R can be used to prepare your data for further analysis, some people find them a bit laborious for daily applications. Therefore, alternatives have been developed, which make data transformation in R easier and also faster. One of these alternatives is the &lt;code&gt;dplyr&lt;/code&gt; package of the &lt;a href=&#34;https://www.tidyverse.org/&#34; target=&#34;_blank&#34;&gt;tidyverse&lt;/a&gt;. It has gained great popularity among R users and being familiar with its syntax can be considered a standard skill in R.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; In the following I give an introduction to some main functions of &lt;code&gt;dplyr&lt;/code&gt;, which I also use extensively at work.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Getting Help, Importing Data and Some More Vocabulary</title>
      <link>https://www.r-econometrics.com/rbasics/help_and_data_import_etc/</link>
      <pubDate>Sun, 06 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/rbasics/help_and_data_import_etc/</guid>
      <description>&lt;div id=&#34;getting-help&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Getting help&lt;/h3&gt;&#xA;&lt;p&gt;An important part of any R package is its documentation. The documentation of any function can be obtained by using &lt;code&gt;?&lt;/code&gt; followed by the name of the function or by using &lt;code&gt;help(&#34;function_name&#34;)&lt;/code&gt;. After the execution of a help command a new page should appear in the lower right window in RStudio. If not, click on the tab &lt;em&gt;Help&lt;/em&gt; in the lower right window. The help page contains the title of the function followed by a short description. For now the most important parts of the documentation are the following:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Preparing Your Workplace for an Analysis</title>
      <link>https://www.r-econometrics.com/rbasics/beforestart/</link>
      <pubDate>Sun, 06 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/rbasics/beforestart/</guid>
      <description>&lt;div id=&#34;create-a-working-directory&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Create a working directory&lt;/h2&gt;&#xA;&lt;p&gt;Usually, people want to keep the folder structure on their computers tidy, so that they and their co-workers understand, which documents and data were used for a particular project – even if that project was finished months ago. This should also be the case when you work with R. Therefore, I recommend to create a new folder for every new project, which becomes the so-called working directory. There you put all the files, which are necessary for a project. For example, for this introduction I created the folder &lt;em&gt;r_intro&lt;/em&gt; in my file explorer and I recommend to do the same on your computer now.&lt;/p&gt;</description>
    </item>
    <item>
      <title>R(eal) Basics</title>
      <link>https://www.r-econometrics.com/rbasicsintro/</link>
      <pubDate>Sun, 06 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/rbasicsintro/</guid>
      <description>&lt;p&gt;This section should help you to&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.r-econometrics.com/rbasics/installation&#34;&gt;get R and RStudio started on your computer&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.r-econometrics.com/rbasics/rstructure&#34;&gt;understand the structure of the program&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.r-econometrics.com/rbasics/beforestart&#34;&gt;prepare your workspace for an analysis&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.r-econometrics.com/rbasics/help_and_data_import_etc&#34;&gt;import data, get help and some more important vocabulary&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.r-econometrics.com/rbasics/dplyrintro&#34;&gt;manipulate data with the &lt;code&gt;dplyr&lt;/code&gt; package&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.r-econometrics.com/rbasics/ggplotintro&#34;&gt;create graphics with the &lt;code&gt;ggplot2&lt;/code&gt; package&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Recently, I have finished the first version of a below 30 pages introduction to R. It uses an exemplary workflow to explain some basics of the language and the application of the packages &lt;code&gt;dplyr&lt;/code&gt;, &lt;code&gt;ggplot2&lt;/code&gt; and &lt;code&gt;openxlsx&lt;/code&gt;. The script can be downloaded &lt;a href=&#34;https://www.r-econometrics.com/2019-mohr-introduction-r.pdf&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Introduction to Vector Error Correction Models (VECMs)</title>
      <link>https://www.r-econometrics.com/timeseries/vecintro/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/timeseries/vecintro/</guid>
      <description>&lt;p&gt;One of the prerequisits for the estimation of a &lt;a href=&#34;https://www.r-econometrics.com/timeseries/varintro&#34;&gt;vector autoregressive (VAR)&lt;/a&gt; model is that the analysed time series are stationary. However, economic theory suggests that there exist equilibrium relations between economic variables in their levels, which can render these variables stationary without taking differences. This is called &lt;em&gt;cointegration&lt;/em&gt;. Since knowing the size of such relationships can improve the results of an analysis, it would be desireable to have an econometric model, which is able to capture them. So-called &lt;em&gt;vector error correction models&lt;/em&gt; (VECMs) belong to this class of models. The following text presents the basic concept of VECMs and guides through the estimation of such a model in R.&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Introduction to Bayesian VAR (BVAR) Models</title>
      <link>https://www.r-econometrics.com/timeseries/bvar/</link>
      <pubDate>Sun, 07 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/timeseries/bvar/</guid>
      <description>&lt;p&gt;Bayesian methods have significantly gained in popularity during the last decades as computers have become more powerful and new software has been developed. Their flexibility and other advantageous features have made these methods also more popular in econometrics. This post gives a brief introduction to Bayesian VAR (BVAR) models and provides the code to set up and estimate a basic model with the &lt;a href=&#34;https://cran.r-project.org/package=bvartools&#34;&gt;&lt;code&gt;bvartools&lt;/code&gt;&lt;/a&gt; package.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bayesian Error Correction Models with Priors on the Cointegration Space</title>
      <link>https://www.r-econometrics.com/timeseries/bvec/</link>
      <pubDate>Tue, 11 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/timeseries/bvec/</guid>
      <description>&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;This post provides the code to set up and estimate a basic Bayesian vector error correction (BVEC) model with the &lt;code&gt;bvartools&lt;/code&gt; package. The presented Gibbs sampler is based on the approach of Koop et al. (2010), who propose a prior on the cointegration space.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Data&lt;/h2&gt;&#xA;&lt;p&gt;To illustrate the estimation process, the dataset E6 from Lütkepohl (2007) is used, which contains data on German long-term interest rates and inflation from 1972Q2 to 1998Q4.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Stochastic Search Variable Selection</title>
      <link>https://www.r-econometrics.com/timeseries/ssvs/</link>
      <pubDate>Tue, 11 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/timeseries/ssvs/</guid>
      <description>&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;A general drawback of vector autoregressive (VAR) models is that the number of estimated coefficients increases disproportionately with the number of lags. Therefore, fewer information per parameter is available for the estimation as the number of lags increases. In the Bayesian VAR literature one approach to mitigate this so-called &lt;em&gt;curse of dimensionality&lt;/em&gt; is &lt;em&gt;stochastic search variable selection&lt;/em&gt; (SSVS) as proposed by George et al. (2008). The basic idea of SSVS is to assign commonly used prior variances to parameters, which should be included in a model, and prior variances close to zero to irrelevant parameters. By that, relevant parameters are estimated in the usual way and posterior draws of irrelevant variables are close to zero so that they have no significant effect on forecasts and impulse responses. This is achieved by adding a hierarchial prior to the model, where the relevance of a variable is assessed in each step of the sampling algorithm.&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Links</title>
      <link>https://www.r-econometrics.com/links/</link>
      <pubDate>Mon, 10 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/links/</guid>
      <description>&lt;div id=&#34;resources-for-learning-r&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Resources for learning R&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://www.r-project.org/&#34; target=&#34;_blank&#34;&gt;R-Project&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://www.rstudio.com/&#34; target=&#34;_blank&#34;&gt;RStudio&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.datacamp.com/&#34; target=&#34;_blank&#34;&gt;DataCamp: Courses on data analysis with R&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://r-statistics.co/&#34; target=&#34;_blank&#34;&gt;Selva Prabhakaran’s r-statistics.co also provides very good intros to R&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://r-exercises.com&#34; target=&#34;_blank&#34;&gt;Great intros to R basics packed into exercises&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://eclr.humanities.manchester.ac.uk/index.php/R&#34; target=&#34;_blank&#34;&gt;Great intro to basic R applications by Ralf Becker and James Lincoln&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://togaware.com/onepager/&#34; target=&#34;_blank&#34;&gt;OnePageR: Compact intro to many methods of data science&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://tryr.codeschool.com/&#34; target=&#34;_blank&#34;&gt;Codeschool: R-Tutorials&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://www.endmemo.com/program/R/index.php&#34; target=&#34;_blank&#34;&gt;Endmemo: R-Tutorials&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://en.wikibooks.org/wiki/R_Programming&#34; target=&#34;_blank&#34;&gt;Wikibook on R Programming&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://en.wikibooks.org/wiki/R_Programming&#34; target=&#34;_blank&#34;&gt;Wikibook on R Programming&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Data&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html&#34; target=&#34;_blank&#34;&gt;Financial portfolio and benchmark data provided by Kenneth R. French&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Reproduction: Timmer, M. P., Dietzenbacher, E., Los, B., Stehrer, R., &amp; De Vries, G. J. (2015). An illustrated user guide to the world input–output database: the case of global automotive production.</title>
      <link>https://www.r-econometrics.com/reproduction/2015_timmer_wiod/</link>
      <pubDate>Mon, 20 May 2019 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/2015_timmer_wiod/</guid>
      <description>&lt;p&gt;As international trade has become increasingly fragmented over the past decades the analysis of global value chains (GVC) has gained popularity in economic research. This post reproduces Timmer et al. (2015), who introduce the world input-output database (WIOD) and present basic concepts of GVC analysis.&lt;/p&gt;&#xA;&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Data&lt;/h2&gt;&#xA;&lt;p&gt;Timmer et al. (2015) use the 2013 vintage of the world input-output database (&lt;a href=&#34;http://www.wiod.org/database/wiots13&#34; target=&#34;_blank&#34;&gt;WIOD&lt;/a&gt;). The following code downloads the data from the project’s website, unzips it and loads the resulting STATA file into R using the &lt;code&gt;readstata13&lt;/code&gt; package.&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Exercise in Growth Accounting</title>
      <link>https://www.r-econometrics.com/2018/12/30/an-exercise-in-growth-accounting/</link>
      <pubDate>Sun, 30 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/2018/12/30/an-exercise-in-growth-accounting/</guid>
      <description>&lt;p&gt;The discipline of growth accounting tries to assess the relative contribution of labour, capital and technology to the economic growth of a country. This post provides a short theoretical introduction to the concept of growth accounting and uses Penn World Table data to calculate total factor productivity (TFP) growth rates for a series of countries using the simple Solow-method.&lt;/p&gt;</description>
    </item>
    <item>
      <title>William Shakespeare&#39;s Work in a Word Cloud</title>
      <link>https://www.r-econometrics.com/2018/12/30/william-shakespeares-work-in-a-word-cloud/</link>
      <pubDate>Sun, 30 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/2018/12/30/william-shakespeares-work-in-a-word-cloud/</guid>
      <description>&lt;p&gt;Word or tag clouds seem to be quite popular at the moment. Although their analytical power might be limited, they do serve an aesthetic purpose and, for example, could be put on the cover page of a thesis or a presentation using the content of your work or the literature you went through. This post uses text data from the Gutenberg project to give a step-by-step introduction on how to create a wordcould in R.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Extracting Cyclical Components From Economic Time Series</title>
      <link>https://www.r-econometrics.com/timeseries/economic-cycle-extraction/</link>
      <pubDate>Thu, 27 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/timeseries/economic-cycle-extraction/</guid>
      <description>&lt;p&gt;The analysis of economic time series often requires the extraction of their cyclical components. This post presents some methods, which can be used to decompose time series into their different components. It is based on the chapter on business cycles by Stock and Watson (1999) in the Handbook of Macroeconomics, but also presents some more recent methods like Hamilton’s (2018) alternative to the HP-filter, wavelet filtering and empirical mode decomposition.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Heteroskedasticity Robust Standard Errors in R</title>
      <link>https://www.r-econometrics.com/methods/hcrobusterrors/</link>
      <pubDate>Mon, 24 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/methods/hcrobusterrors/</guid>
      <description>&lt;p&gt;Although heteroskedasticity does not produce biased &lt;a href=&#34;https://www.r-econometrics.com/methods/ols&#34;&gt;OLS&lt;/a&gt; estimates, it leads to a bias in the variance-covariance matrix. This means that standard model testing methods such as t tests or F tests cannot be relied on any longer. This post provides an intuitive illustration of heteroskedasticity and covers the calculation of standard errors that are robust to it.&lt;/p&gt;&#xA;&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Data&lt;/h2&gt;&#xA;&lt;p&gt;A popular illustration of heteroskedasticity is the relationship between saving and income, which is shown in the following graph. The dataset is contained the &lt;em&gt;wooldridge&lt;/em&gt; package.&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chan et al. (2019): Bayesian Econometric Methods</title>
      <link>https://www.r-econometrics.com/reproduction/bayesmethods/bayesmethodsintro/</link>
      <pubDate>Sat, 01 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/bayesmethods/bayesmethodsintro/</guid>
      <description>&lt;p&gt;This section is based on Chan et al. (2019). Bayesian econometric methods (2&lt;sup&gt;nd&lt;/sup&gt;ed.). The following links contain examples in the main text of the book and use R to estimate the models.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.r-econometrics.com/reproduction/bayesmethods/bayesmethods11&#34;&gt;Chapter 11: Monte Carlo Integration&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.r-econometrics.com/reproduction/bayesmethods/bayesmethods18&#34;&gt;Chapter 18: State Space and Unobserved Components Models&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.r-econometrics.com/reproduction/bayesmethods/bayesmethods20&#34;&gt;Chapter 20: Multivariate Time Series Methods&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chapter 8: Heteroskedasticity</title>
      <link>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge08/</link>
      <pubDate>Sat, 01 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge08/</guid>
      <description>&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(wooldridge)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;div id=&#34;example-8.1&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Example 8.1&lt;/h3&gt;&#xA;&lt;p&gt;After loading the data and generating the dummy variables from chapter 7 estimate the model in the already familiar way.&lt;/p&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;wage1&amp;quot;)&#xA;&#xA;marrmale &amp;lt;- as.numeric(wage1$female == 0 &amp;amp; wage1$married == 1)&#xA;marrfem &amp;lt;- as.numeric(wage1$female == 1 &amp;amp; wage1$married == 1)&#xA;singfem &amp;lt;- as.numeric(wage1$female == 1 &amp;amp; wage1$married == 0)&#xA;&#xA;lm.8.1 &amp;lt;- lm(lwage ~ marrmale + marrfem + singfem + educ + exper + expersq + tenure + tenursq, data = wage1)&#xA;&#xA;summary(lm.8.1)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = lwage ~ marrmale + marrfem + singfem + educ + exper + &#xA;##     expersq + tenure + tenursq, data = wage1)&#xA;## &#xA;## Residuals:&#xA;##      Min       1Q   Median       3Q      Max &#xA;## -1.89697 -0.24060 -0.02689  0.23144  1.09197 &#xA;## &#xA;## Coefficients:&#xA;##               Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)  0.3213781  0.1000090   3.213 0.001393 ** &#xA;## marrmale     0.2126757  0.0553572   3.842 0.000137 ***&#xA;## marrfem     -0.1982676  0.0578355  -3.428 0.000656 ***&#xA;## singfem     -0.1103502  0.0557421  -1.980 0.048272 *  &#xA;## educ         0.0789103  0.0066945  11.787  &amp;lt; 2e-16 ***&#xA;## exper        0.0268006  0.0052428   5.112 4.50e-07 ***&#xA;## expersq     -0.0005352  0.0001104  -4.847 1.66e-06 ***&#xA;## tenure       0.0290875  0.0067620   4.302 2.03e-05 ***&#xA;## tenursq     -0.0005331  0.0002312  -2.306 0.021531 *  &#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 0.3933 on 517 degrees of freedom&#xA;## Multiple R-squared:  0.4609, Adjusted R-squared:  0.4525 &#xA;## F-statistic: 55.25 on 8 and 517 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;The function &lt;code&gt;coeftest&lt;/code&gt; from the &lt;code&gt;lmtest&lt;/code&gt; package can be used to obtain the heteroskedasticity robust standard errors. The first argument of the function contains the result of the original estimation, i.e. &lt;code&gt;lm.8.1.&lt;/code&gt;. The second argument tells R how to calculate the heteroskedasticity robust standard errors. Basically, you could just enter the first part and R would do the rest. However, since the standard procedure of &lt;code&gt;coeftest&lt;/code&gt; would not give the same results as in the book, we have to specify them a bit. Thus, we use the &lt;code&gt;vcovHC&lt;/code&gt; function from the &lt;code&gt;sandwich&lt;/code&gt; package, which requires the output of the estimated model and a specification of the type of robust standard errors that should be calculated. In our case we want a simple White standard error, which is indicated by &lt;code&gt;type = &amp;quot;HC0&amp;quot;&lt;/code&gt;. Other, more sophisticated methods are described in the documentation of the function.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Econometric Methods</title>
      <link>https://www.r-econometrics.com/methodsintro/</link>
      <pubDate>Mon, 08 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/methodsintro/</guid>
      <description>&lt;p&gt;This section is intended to get you through your undergraduate (and maybe graduate) studies in econometrics. It is based on examples from Wooldridge, J.M. (2013). Introductory econometrics: A modern approach (5&lt;sup&gt;th&lt;/sup&gt;ed.). I have also reproduced the examples of the main text, which you can find in the &lt;a href=&#34;https://www.r-econometrics.com/reproduction/wooldridge/wooldridgeintro&#34;&gt;reproduction section of the site&lt;/a&gt;. Alternatively, &lt;a href=&#34;http://urfie.net/&#34;&gt;Heiss, F. (2016) Using R for Introductory Econometrics&lt;/a&gt; is a standalone textbook, which covers the same topics as Wooldridge (2013) and provides an introduction to R as well.&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Introduction to Ordinary Least Squares (OLS) in R</title>
      <link>https://www.r-econometrics.com/methods/ols/</link>
      <pubDate>Sun, 07 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/methods/ols/</guid>
      <description>&lt;p&gt;Formulated at the beginning of the 19th century by Legendre and Gauss the method of &lt;a href=&#34;https://en.wikipedia.org/wiki/Least_squares&#34; target=&#34;_blank&#34;&gt;least squares&lt;/a&gt; is a standard tool in econometrics to assess the relationships between different variables. This site gives a short introduction to the basic idea behind the method and describes how to estimate simple linear models with OLS in R.&lt;/p&gt;&#xA;&lt;div id=&#34;the-method-of-least-squares&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;The method of least squares&lt;/h2&gt;&#xA;&lt;p&gt;To understand the basic idea of the method of least squares, imagine you were an astronomer at the beginning of the 19th century, who faced the challenge of combining a series of observations, which were made with imperfect instruments and at different points in time.&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; One day you draw a scatter plot, which looks similar to the following:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chapter 10: Basic Regression Analysis with Time Series Data</title>
      <link>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge10/</link>
      <pubDate>Sun, 07 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge10/</guid>
      <description>&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(wooldridge)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;div id=&#34;example-10.1&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Example 10.1&lt;/h3&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;phillips&amp;quot;)&#xA;&#xA;lm.10.1 &amp;lt;- lm(inf ~ unem, data = phillips)&#xA;summary(lm.10.1)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = inf ~ unem, data = phillips)&#xA;## &#xA;## Residuals:&#xA;##     Min      1Q  Median      3Q     Max &#xA;## -5.2176 -1.7812 -0.6659  1.1473  8.8795 &#xA;## &#xA;## Coefficients:&#xA;##             Estimate Std. Error t value Pr(&amp;gt;|t|)  &#xA;## (Intercept)   1.0536     1.5480   0.681   0.4990  &#xA;## unem          0.5024     0.2656   1.892   0.0639 .&#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 2.972 on 54 degrees of freedom&#xA;## Multiple R-squared:  0.06215,    Adjusted R-squared:  0.04479 &#xA;## F-statistic: 3.579 on 1 and 54 DF,  p-value: 0.06389&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div id=&#34;example-10.2&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Example 10.2&lt;/h3&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;intdef&amp;quot;)&#xA;&#xA;lm.10.2 &amp;lt;- lm(i3 ~ inf + def, data = intdef)&#xA;summary(lm.10.2)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = i3 ~ inf + def, data = intdef)&#xA;## &#xA;## Residuals:&#xA;##     Min      1Q  Median      3Q     Max &#xA;## -3.9948 -1.1694  0.1959  0.9602  4.7224 &#xA;## &#xA;## Coefficients:&#xA;##             Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)  1.73327    0.43197   4.012  0.00019 ***&#xA;## inf          0.60587    0.08213   7.376 1.12e-09 ***&#xA;## def          0.51306    0.11838   4.334 6.57e-05 ***&#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 1.843 on 53 degrees of freedom&#xA;## Multiple R-squared:  0.6021, Adjusted R-squared:  0.5871 &#xA;## F-statistic: 40.09 on 2 and 53 DF,  p-value: 2.483e-11&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div id=&#34;example-10.3&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Example 10.3&lt;/h3&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;prminwge&amp;quot;)&#xA;&#xA;lm.10.3 &amp;lt;- lm(lprepop ~ lmincov + lusgnp, data = prminwge)&#xA;summary(lm.10.3)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = lprepop ~ lmincov + lusgnp, data = prminwge)&#xA;## &#xA;## Residuals:&#xA;##       Min        1Q    Median        3Q       Max &#xA;## -0.117133 -0.036998 -0.005943  0.028182  0.113938 &#xA;## &#xA;## Coefficients:&#xA;##             Estimate Std. Error t value Pr(&amp;gt;|t|)  &#xA;## (Intercept) -1.05442    0.76541  -1.378   0.1771  &#xA;## lmincov     -0.15444    0.06490  -2.380   0.0229 *&#xA;## lusgnp      -0.01219    0.08851  -0.138   0.8913  &#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 0.0557 on 35 degrees of freedom&#xA;## Multiple R-squared:  0.6605, Adjusted R-squared:  0.6411 &#xA;## F-statistic: 34.04 on 2 and 35 DF,  p-value: 6.17e-09&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div id=&#34;example-10.4&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Example 10.4&lt;/h3&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;fertil3&amp;quot;)&#xA;&#xA;lm.10.4.1 &amp;lt;- lm(gfr ~ pe + ww2 + pill, data = fertil3)&#xA;summary(lm.10.4.1)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = gfr ~ pe + ww2 + pill, data = fertil3)&#xA;## &#xA;## Residuals:&#xA;##      Min       1Q   Median       3Q      Max &#xA;## -27.0187  -9.6195   0.3393   9.4746  28.0730 &#xA;## &#xA;## Coefficients:&#xA;##              Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)  98.68176    3.20813  30.760  &amp;lt; 2e-16 ***&#xA;## pe            0.08254    0.02965   2.784  0.00694 ** &#xA;## ww2         -24.23840    7.45825  -3.250  0.00180 ** &#xA;## pill        -31.59403    4.08107  -7.742 6.46e-11 ***&#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 14.69 on 68 degrees of freedom&#xA;## Multiple R-squared:  0.4734, Adjusted R-squared:  0.4502 &#xA;## F-statistic: 20.38 on 3 and 68 DF,  p-value: 1.575e-09&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm.10.4.2 &amp;lt;- lm(gfr ~ pe + pe_1 + pe_2 + ww2 + pill, data = fertil3)&#xA;summary(lm.10.4.2)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = gfr ~ pe + pe_1 + pe_2 + ww2 + pill, data = fertil3)&#xA;## &#xA;## Residuals:&#xA;##      Min       1Q   Median       3Q      Max &#xA;## -24.6461  -9.5409  -0.0312   8.3378  29.1295 &#xA;## &#xA;## Coefficients:&#xA;##              Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)  95.87050    3.28196  29.211  &amp;lt; 2e-16 ***&#xA;## pe            0.07267    0.12553   0.579   0.5647    &#xA;## pe_1         -0.00578    0.15566  -0.037   0.9705    &#xA;## pe_2          0.03383    0.12626   0.268   0.7896    &#xA;## ww2         -22.12650   10.73197  -2.062   0.0433 *  &#xA;## pill        -31.30499    3.98156  -7.862 5.63e-11 ***&#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 14.27 on 64 degrees of freedom&#xA;##   (2 observations deleted due to missingness)&#xA;## Multiple R-squared:  0.4986, Adjusted R-squared:  0.4594 &#xA;## F-statistic: 12.73 on 5 and 64 DF,  p-value: 1.353e-08&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Joint significance of pe values&#xA;lm.10.4.2res &amp;lt;- lm(gfr ~ ww2 + pill, data = fertil3, subset = (is.na(pe_2) == FALSE))&#xA;anova(lm.10.4.2, lm.10.4.2res)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table&#xA;## &#xA;## Model 1: gfr ~ pe + pe_1 + pe_2 + ww2 + pill&#xA;## Model 2: gfr ~ ww2 + pill&#xA;##   Res.Df   RSS Df Sum of Sq     F  Pr(&amp;gt;F)  &#xA;## 1     64 13033                             &#xA;## 2     67 15460 -3   -2427.1 3.973 0.01165 *&#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Joint significance of lagged pe values&#xA;lm.10.4.2res2 &amp;lt;- lm(gfr ~ pe + ww2 + pill, data = fertil3, subset = (is.na(pe_2) == FALSE))&#xA;anova(lm.10.4.2, lm.10.4.2res2)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table&#xA;## &#xA;## Model 1: gfr ~ pe + pe_1 + pe_2 + ww2 + pill&#xA;## Model 2: gfr ~ pe + ww2 + pill&#xA;##   Res.Df   RSS Df Sum of Sq      F Pr(&amp;gt;F)&#xA;## 1     64 13033                           &#xA;## 2     66 13054 -2   -21.761 0.0534  0.948&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Standard error of the long run propensity&#xA;summary(lm(gfr ~ pe + I(pe_1 - pe) + I(pe_2 - pe_1) + ww2 + pill, data = fertil3))&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = gfr ~ pe + I(pe_1 - pe) + I(pe_2 - pe_1) + ww2 + &#xA;##     pill, data = fertil3)&#xA;## &#xA;## Residuals:&#xA;##      Min       1Q   Median       3Q      Max &#xA;## -24.6461  -9.5409  -0.0312   8.3378  29.1295 &#xA;## &#xA;## Coefficients:&#xA;##                 Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)     95.87050    3.28196  29.211  &amp;lt; 2e-16 ***&#xA;## pe               0.10072    0.02980   3.380  0.00124 ** &#xA;## I(pe_1 - pe)     0.02805    0.11890   0.236  0.81427    &#xA;## I(pe_2 - pe_1)   0.03383    0.12626   0.268  0.78962    &#xA;## ww2            -22.12650   10.73197  -2.062  0.04330 *  &#xA;## pill           -31.30499    3.98156  -7.862 5.63e-11 ***&#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 14.27 on 64 degrees of freedom&#xA;##   (2 observations deleted due to missingness)&#xA;## Multiple R-squared:  0.4986, Adjusted R-squared:  0.4594 &#xA;## F-statistic: 12.73 on 5 and 64 DF,  p-value: 1.353e-08&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div id=&#34;example-10.5&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Example 10.5&lt;/h3&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;barium&amp;quot;)&#xA;&#xA;lm.10.5 &amp;lt;- lm(lchnimp ~ lchempi + lgas + lrtwex + befile6 + affile6 + afdec6, data = barium)&#xA;summary(lm.10.5)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = lchnimp ~ lchempi + lgas + lrtwex + befile6 + affile6 + &#xA;##     afdec6, data = barium)&#xA;## &#xA;## Residuals:&#xA;##      Min       1Q   Median       3Q      Max &#xA;## -2.03356 -0.39080  0.03048  0.40248  1.51719 &#xA;## &#xA;## Coefficients:&#xA;##              Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept) -17.80300   21.04537  -0.846   0.3992    &#xA;## lchempi       3.11719    0.47920   6.505 1.72e-09 ***&#xA;## lgas          0.19635    0.90662   0.217   0.8289    &#xA;## lrtwex        0.98302    0.40015   2.457   0.0154 *  &#xA;## befile6       0.05957    0.26097   0.228   0.8198    &#xA;## affile6      -0.03241    0.26430  -0.123   0.9026    &#xA;## afdec6       -0.56524    0.28584  -1.978   0.0502 .  &#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 0.5974 on 124 degrees of freedom&#xA;## Multiple R-squared:  0.3049, Adjusted R-squared:  0.2712 &#xA;## F-statistic: 9.064 on 6 and 124 DF,  p-value: 3.255e-08&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div id=&#34;example-10.6&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Example 10.6&lt;/h3&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;fair&amp;quot;)&#xA;&#xA;lm.10.6 &amp;lt;- lm(demvote ~ partyWH + incum + I(partyWH*gnews) + I(partyWH*inf), data = fair)&#xA;summary(lm.10.6)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = demvote ~ partyWH + incum + I(partyWH * gnews) + &#xA;##     I(partyWH * inf), data = fair)&#xA;## &#xA;## Residuals:&#xA;##       Min        1Q    Median        3Q       Max &#xA;## -0.059843 -0.035554 -0.001095  0.015049  0.104859 &#xA;## &#xA;## Coefficients:&#xA;##                     Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)         0.484219   0.011472  42.210   &amp;lt;2e-16 ***&#xA;## partyWH            -0.032380   0.037550  -0.862   0.4013    &#xA;## incum               0.056369   0.023017   2.449   0.0262 *  &#xA;## I(partyWH * gnews)  0.009666   0.003807   2.539   0.0219 *  &#xA;## I(partyWH * inf)   -0.008338   0.003121  -2.672   0.0167 *  &#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 0.049 on 16 degrees of freedom&#xA;## Multiple R-squared:  0.6588, Adjusted R-squared:  0.5735 &#xA;## F-statistic: 7.725 on 4 and 16 DF,  p-value: 0.001151&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Slightly different results since the book uses 20 observations to 1992. But the results are the same when we drop the last observation.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chapter 11: Further Issues in Using OLS with Time Series Data</title>
      <link>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge11/</link>
      <pubDate>Sun, 07 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge11/</guid>
      <description>&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(wooldridge)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;div id=&#34;example-11.4&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Example 11.4&lt;/h3&gt;&#xA;&lt;p&gt;For this regression the lagged values of return are already contained in the dataset. Thus, we do not have to calculated them ourselves and can simply run the regression.&lt;/p&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;nyse&amp;quot;)&#xA;&#xA;lm.11.4  &amp;lt;-  lm(return ~ return_1, data = nyse)&#xA;summary(lm.11.4)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = return ~ return_1, data = nyse)&#xA;## &#xA;## Residuals:&#xA;##     Min      1Q  Median      3Q     Max &#xA;## -15.261  -1.302   0.098   1.316   8.065 &#xA;## &#xA;## Coefficients:&#xA;##             Estimate Std. Error t value Pr(&amp;gt;|t|)  &#xA;## (Intercept)  0.17963    0.08074   2.225   0.0264 *&#xA;## return_1     0.05890    0.03802   1.549   0.1218  &#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 2.11 on 687 degrees of freedom&#xA;##   (2 observations deleted due to missingness)&#xA;## Multiple R-squared:  0.003481,   Adjusted R-squared:  0.00203 &#xA;## F-statistic: 2.399 on 1 and 687 DF,  p-value: 0.1218&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div id=&#34;equation-11.17&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Equation 11.17&lt;/h3&gt;&#xA;&lt;p&gt;To estimate this model we have to calculate the lagged values ourselves. First, I created a vector of the return values from the nyse data set. To create the series with the first lagged returns I omitted the first value in the list of returns of the nyse data set by adding [-1]. But since this causes the length of the resulting series to decrease by one observation, we have to add an NA so that R can estimate the model. I added this NA by creating a list with c() which contains the values from the first lag list “nyse$return[-1]” and put an NA at the end. For the second list of lagged values I proceeded similarly. I omitted the first and second observation from the return list of the nyse data set and added two NAs. The estimation works as usual.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chapter 16: Simultaneous Equations Models</title>
      <link>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge16/</link>
      <pubDate>Sun, 07 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge16/</guid>
      <description>&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(AER)&#xA;library(wooldridge)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;div id=&#34;example-16.5&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Example 16.5&lt;/h3&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;mroz&amp;quot;)&#xA;&#xA;s.iv.1 &amp;lt;- summary(iv.1 &amp;lt;- ivreg(hours ~ lwage + educ + age + kidslt6 + nwifeinc |&#xA;                                  educ + age + kidslt6 + nwifeinc + exper + expersq,&#xA;                                data = mroz))&#xA;s.iv.1&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## ivreg(formula = hours ~ lwage + educ + age + kidslt6 + nwifeinc | &#xA;##     educ + age + kidslt6 + nwifeinc + exper + expersq, data = mroz)&#xA;## &#xA;## Residuals:&#xA;##      Min       1Q   Median       3Q      Max &#xA;## -4570.13  -654.08   -36.94   569.86  8372.91 &#xA;## &#xA;## Coefficients:&#xA;##             Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept) 2225.662    574.564   3.874 0.000124 ***&#xA;## lwage       1639.556    470.576   3.484 0.000545 ***&#xA;## educ        -183.751     59.100  -3.109 0.002003 ** &#xA;## age           -7.806      9.378  -0.832 0.405664    &#xA;## kidslt6     -198.154    182.929  -1.083 0.279325    &#xA;## nwifeinc     -10.170      6.615  -1.537 0.124942    &#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 1354 on 422 degrees of freedom&#xA;## Multiple R-Squared: -2.008,  Adjusted R-squared: -2.043 &#xA;## Wald test: 3.441 on 5 and 422 DF,  p-value: 0.004648&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm.1 &amp;lt;- lm(lwage ~ educ + age + kidslt6 + nwifeinc + exper + expersq,&#xA;           data = mroz[mroz$inlf==1,])&#xA;&#xA;lm.2 &amp;lt;- lm(hours ~ lwage + educ + age + kidslt6 + nwifeinc + lm.1$residuals,&#xA;           data = mroz[mroz$inlf==1,])&#xA;&#xA;summary(lm.2)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = hours ~ lwage + educ + age + kidslt6 + nwifeinc + &#xA;##     lm.1$residuals, data = mroz[mroz$inlf == 1, ])&#xA;## &#xA;## Residuals:&#xA;##     Min      1Q  Median      3Q     Max &#xA;## -1600.5  -548.6   107.7   461.4  3075.2 &#xA;## &#xA;## Coefficients:&#xA;##                 Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)     2225.662    309.976   7.180 3.18e-12 ***&#xA;## lwage           1639.556    253.875   6.458 2.93e-10 ***&#xA;## educ            -183.751     31.884  -5.763 1.60e-08 ***&#xA;## age               -7.806      5.059  -1.543  0.12361    &#xA;## kidslt6         -198.154     98.690  -2.008  0.04530 *  &#xA;## nwifeinc         -10.170      3.569  -2.850  0.00459 ** &#xA;## lm.1$residuals -1714.358    259.439  -6.608 1.18e-10 ***&#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 730.6 on 421 degrees of freedom&#xA;## Multiple R-squared:  0.1267, Adjusted R-squared:  0.1142 &#xA;## F-statistic: 10.18 on 6 and 421 DF,  p-value: 1.592e-10&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div id=&#34;example-16.6&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Example 16.6&lt;/h3&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;openness&amp;quot;)&#xA;&#xA;s.lm.1 &amp;lt;- summary(lm.1 &amp;lt;- lm(open ~ lpcinc + lland, data = openness))&#xA;s.lm.1&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = open ~ lpcinc + lland, data = openness)&#xA;## &#xA;## Residuals:&#xA;##     Min      1Q  Median      3Q     Max &#xA;## -31.907  -8.843  -3.109   6.057  82.792 &#xA;## &#xA;## Coefficients:&#xA;##             Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept) 117.0845    15.8483   7.388 2.97e-11 ***&#xA;## lpcinc        0.5465     1.4932   0.366    0.715    &#xA;## lland        -7.5671     0.8142  -9.294 1.51e-15 ***&#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 17.8 on 111 degrees of freedom&#xA;## Multiple R-squared:  0.4487, Adjusted R-squared:  0.4387 &#xA;## F-statistic: 45.17 on 2 and 111 DF,  p-value: 4.451e-15&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s.iv.1 &amp;lt;- summary(iv.1 &amp;lt;- ivreg(inf ~ open +lpcinc |&#xA;                                  lpcinc + lland,&#xA;                                data = openness))&#xA;s.iv.1&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## ivreg(formula = inf ~ open + lpcinc | lpcinc + lland, data = openness)&#xA;## &#xA;## Residuals:&#xA;##     Min      1Q  Median      3Q     Max &#xA;## -21.686 -10.176  -5.857   2.912 184.875 &#xA;## &#xA;## Coefficients:&#xA;##             Estimate Std. Error t value Pr(&amp;gt;|t|)  &#xA;## (Intercept)  26.8993    15.4012   1.747   0.0835 .&#xA;## open         -0.3375     0.1441  -2.342   0.0210 *&#xA;## lpcinc        0.3758     2.0151   0.187   0.8524  &#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 23.84 on 111 degrees of freedom&#xA;## Multiple R-Squared: 0.03088, Adjusted R-squared: 0.01341 &#xA;## Wald test:  2.79 on 2 and 111 DF,  p-value: 0.06574&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div id=&#34;example-16.7&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Example 16.7&lt;/h3&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;consump&amp;quot;)&#xA;&#xA;s.iv.1 &amp;lt;- summary(iv.1 &amp;lt;- ivreg(gc ~ gy + r3 |&#xA;                                  gc_1 + gy_1 +r3_1,&#xA;                                data = consump))&#xA;s.iv.1&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## ivreg(formula = gc ~ gy + r3 | gc_1 + gy_1 + r3_1, data = consump)&#xA;## &#xA;## Residuals:&#xA;##        Min         1Q     Median         3Q        Max &#xA;## -0.0135627 -0.0035412 -0.0006202  0.0036514  0.0128639 &#xA;## &#xA;## Coefficients:&#xA;##               Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)  0.0080597  0.0032327   2.493 0.018026 *  &#xA;## gy           0.5861880  0.1345737   4.356 0.000128 ***&#xA;## r3          -0.0002694  0.0007640  -0.353 0.726698    &#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 0.007471 on 32 degrees of freedom&#xA;## Multiple R-Squared: 0.6779,  Adjusted R-squared: 0.6578 &#xA;## Wald test: 9.586 on 2 and 32 DF,  p-value: 0.0005468&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div id=&#34;example-16.8&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Example 16.8&lt;/h3&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;prison&amp;quot;)&#xA;&#xA;s.lm.1 &amp;lt;- summary(lm.1 &amp;lt;- lm(gcriv ~ y81 + y82 + y83 + y84 + y85 + y86 + y87 + y88 +&#xA;                               y89 + y90 + y91 + y92 + y93 + gpris + gpolpc + gincpc +&#xA;                               cunem + cblack + cmetro + cag0_14 + cag15_17 + cag18_24 +&#xA;                               cag25_34,&#xA;                             data = prison))&#xA;s.lm.1&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = gcriv ~ y81 + y82 + y83 + y84 + y85 + y86 + y87 + &#xA;##     y88 + y89 + y90 + y91 + y92 + y93 + gpris + gpolpc + gincpc + &#xA;##     cunem + cblack + cmetro + cag0_14 + cag15_17 + cag18_24 + &#xA;##     cag25_34, data = prison)&#xA;## &#xA;## Residuals:&#xA;##      Min       1Q   Median       3Q      Max &#xA;## -0.32282 -0.04186  0.00283  0.04109  0.50580 &#xA;## &#xA;## Coefficients:&#xA;##              Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept) -0.005671   0.021558  -0.263 0.792597    &#xA;## y81         -0.068626   0.017409  -3.942 8.91e-05 ***&#xA;## y82         -0.040773   0.020196  -2.019 0.043894 *  &#xA;## y83         -0.042178   0.019804  -2.130 0.033550 *  &#xA;## y84         -0.013660   0.022350  -0.611 0.541290    &#xA;## y85          0.009404   0.020782   0.453 0.651037    &#xA;## y86          0.044095   0.022736   1.939 0.052854 .  &#xA;## y87         -0.023960   0.021713  -1.103 0.270212    &#xA;## y88          0.034758   0.021613   1.608 0.108253    &#xA;## y89          0.025357   0.021867   1.160 0.246603    &#xA;## y90          0.087170   0.021185   4.115 4.35e-05 ***&#xA;## y91          0.038884   0.021359   1.821 0.069111 .  &#xA;## y92          0.008150   0.022659   0.360 0.719183    &#xA;## y93          0.008714   0.024004   0.363 0.716698    &#xA;## gpris       -0.180897   0.047628  -3.798 0.000159 ***&#xA;## gpolpc       0.051424   0.055516   0.926 0.354619    &#xA;## gincpc       0.738368   0.166378   4.438 1.06e-05 ***&#xA;## cunem        0.411260   0.393670   1.045 0.296536    &#xA;## cblack      -0.014743   0.033157  -0.445 0.656708    &#xA;## cmetro       0.538306   0.995660   0.541 0.588922    &#xA;## cag0_14      0.989306   2.006539   0.493 0.622140    &#xA;## cag15_17     4.983840   4.740475   1.051 0.293472    &#xA;## cag18_24     2.412758   2.191017   1.101 0.271192    &#xA;## cag25_34     2.879946   2.228829   1.292 0.196743    &#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 0.07893 on 690 degrees of freedom&#xA;## Multiple R-squared:  0.2311, Adjusted R-squared:  0.2055 &#xA;## F-statistic: 9.019 on 23 and 690 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s.iv.1 &amp;lt;- summary(iv.1 &amp;lt;- ivreg(gcriv ~ y81 + y82 + y83 + y84 + y85 + y86 + y87 + y88 +&#xA;                                  y89 + y90 + y91 + y92 + y93 + gpris + gpolpc + gincpc +&#xA;                                  cunem + cblack + cmetro + cag0_14 + cag15_17 + cag18_24 +&#xA;                                  cag25_34 |&#xA;                                  y81 + y82 + y83 + y84 + y85 + y86 + y87 + y88 +&#xA;                                  y89 + y90 + y91 + y92 + y93 + gpolpc + gincpc +&#xA;                                  cunem + cblack + cmetro + cag0_14 + cag15_17 + cag18_24 +&#xA;                                  cag25_34 + final1 + final2,&#xA;                                data = prison))&#xA;s.iv.1&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## ivreg(formula = gcriv ~ y81 + y82 + y83 + y84 + y85 + y86 + y87 + &#xA;##     y88 + y89 + y90 + y91 + y92 + y93 + gpris + gpolpc + gincpc + &#xA;##     cunem + cblack + cmetro + cag0_14 + cag15_17 + cag18_24 + &#xA;##     cag25_34 | y81 + y82 + y83 + y84 + y85 + y86 + y87 + y88 + &#xA;##     y89 + y90 + y91 + y92 + y93 + gpolpc + gincpc + cunem + cblack + &#xA;##     cmetro + cag0_14 + cag15_17 + cag18_24 + cag25_34 + final1 + &#xA;##     final2, data = prison)&#xA;## &#xA;## Residuals:&#xA;##        Min         1Q     Median         3Q        Max &#xA;## -0.3863488 -0.0567073 -0.0002044  0.0509309  0.4133336 &#xA;## &#xA;## Coefficients:&#xA;##              Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)  0.014838   0.027520   0.539  0.58995    &#xA;## y81         -0.056073   0.021735  -2.580  0.01009 *  &#xA;## y82          0.028462   0.038477   0.740  0.45973    &#xA;## y83          0.024703   0.037397   0.661  0.50911    &#xA;## y84          0.012870   0.029334   0.439  0.66098    &#xA;## y85          0.035403   0.027502   1.287  0.19844    &#xA;## y86          0.092186   0.034388   2.681  0.00752 ** &#xA;## y87          0.004771   0.029015   0.164  0.86944    &#xA;## y88          0.053271   0.027322   1.950  0.05161 .  &#xA;## y89          0.043086   0.027520   1.566  0.11790    &#xA;## y90          0.144265   0.035462   4.068 5.29e-05 ***&#xA;## y91          0.061848   0.027650   2.237  0.02562 *  &#xA;## y92          0.026657   0.028533   0.934  0.35050    &#xA;## y93          0.022274   0.029610   0.752  0.45216    &#xA;## gpris       -1.031956   0.369963  -2.789  0.00543 ** &#xA;## gpolpc       0.035315   0.067499   0.523  0.60101    &#xA;## gincpc       0.910199   0.214327   4.247 2.47e-05 ***&#xA;## cunem        0.523696   0.478563   1.094  0.27420    &#xA;## cblack      -0.015848   0.040104  -0.395  0.69285    &#xA;## cmetro      -0.591517   1.298252  -0.456  0.64880    &#xA;## cag0_14      3.379384   2.634893   1.283  0.20008    &#xA;## cag15_17     3.549945   5.766302   0.616  0.53834    &#xA;## cag18_24     3.358348   2.680839   1.253  0.21073    &#xA;## cag25_34     2.319993   2.706345   0.857  0.39161    &#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 0.09547 on 690 degrees of freedom&#xA;## Multiple R-Squared: -0.1246, Adjusted R-squared: -0.1621 &#xA;## Wald test: 6.075 on 23 and 690 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Chapter 17: Limited Dependent Variable Models and Sample Selection Corrections</title>
      <link>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge17/</link>
      <pubDate>Sun, 07 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge17/</guid>
      <description>&lt;div id=&#34;example-17.1&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Example 17.1&lt;/h3&gt;&#xA;&lt;p&gt;First, look at the linear model.&lt;/p&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;mroz&amp;quot;)&#xA;&#xA;lm.17.1 &amp;lt;- lm(inlf ~ nwifeinc + educ + exper + expersq + age +&#xA;                kidslt6 + kidsge6, data = mroz)&#xA;summary(lm.17.1)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = inlf ~ nwifeinc + educ + exper + expersq + age + &#xA;##     kidslt6 + kidsge6, data = mroz)&#xA;## &#xA;## Residuals:&#xA;##      Min       1Q   Median       3Q      Max &#xA;## -0.93432 -0.37526  0.08833  0.34404  0.99417 &#xA;## &#xA;## Coefficients:&#xA;##               Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)  0.5855192  0.1541780   3.798 0.000158 ***&#xA;## nwifeinc    -0.0034052  0.0014485  -2.351 0.018991 *  &#xA;## educ         0.0379953  0.0073760   5.151 3.32e-07 ***&#xA;## exper        0.0394924  0.0056727   6.962 7.38e-12 ***&#xA;## expersq     -0.0005963  0.0001848  -3.227 0.001306 ** &#xA;## age         -0.0160908  0.0024847  -6.476 1.71e-10 ***&#xA;## kidslt6     -0.2618105  0.0335058  -7.814 1.89e-14 ***&#xA;## kidsge6      0.0130122  0.0131960   0.986 0.324415    &#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 0.4271 on 745 degrees of freedom&#xA;## Multiple R-squared:  0.2642, Adjusted R-squared:  0.2573 &#xA;## F-statistic: 38.22 on 7 and 745 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;To calculated the percentage share of correct predictions I create dummy variables, which equal unity when the fitted values are above or equal to 0.5 and zero else. Next, I create a vector of dummies that are unity when both the fitted prediction and the observation of the dependent variable are unity. If they have different values, i.e. (1,0) or (0,1), the dummy is zero. The mean of this latter vector gives the percentage share of correctly predicted observations.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chapter12: Serial Correlation and Heteroskedasticity in Time Series Regressions</title>
      <link>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge12/</link>
      <pubDate>Sun, 07 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge12/</guid>
      <description>&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(lmtest)&#xA;library(sandwich)&#xA;library(tseries)&#xA;library(wooldridge)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;div id=&#34;example-12.1&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Example 12.1&lt;/h3&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;phillips&amp;quot;)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Static Phillips curve&lt;/p&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm.12.1.1 &amp;lt;- lm(inf ~ unem, data = phillips)&#xA;res.static &amp;lt;- lm.12.1.1$res&#xA;res.static_1 &amp;lt;- c(NA, lm.12.1.1$res[-(length(res.static))])&#xA;lm.12.1.1.test &amp;lt;- lm(res.static ~ res.static_1)&#xA;summary(lm.12.1.1.test)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = res.static ~ res.static_1)&#xA;## &#xA;## Residuals:&#xA;##    Min     1Q Median     3Q    Max &#xA;## -8.047 -1.104 -0.248  1.028  6.684 &#xA;## &#xA;## Coefficients:&#xA;##              Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)   -0.1118     0.3180  -0.352    0.727    &#xA;## res.static_1   0.5725     0.1084   5.283 2.43e-06 ***&#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 2.358 on 53 degrees of freedom&#xA;##   (1 observation deleted due to missingness)&#xA;## Multiple R-squared:  0.345,  Adjusted R-squared:  0.3326 &#xA;## F-statistic: 27.91 on 1 and 53 DF,  p-value: 2.43e-06&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Augmented Phillips curve&lt;/p&gt;</description>
    </item>
    <item>
      <title>Reproduction Projects</title>
      <link>https://www.r-econometrics.com/reproductionintro/</link>
      <pubDate>Sun, 07 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproductionintro/</guid>
      <description>&lt;p&gt;Chan, J. C. C., Koop, G., Poirier, D. J., &amp;amp; Tobias, J. L. (2019). &lt;a href=&#34;https://www.r-econometrics.com/reproduction/bayesmethods/bayesmethodsintro&#34;&gt;Bayesian econometric methods&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Cincera, M. (1997). &lt;a href=&#34;https://www.r-econometrics.com/reproduction/1997_cincera_patents&#34;&gt;Patents, R&amp;amp;D, and technological spillovers at the firm level&lt;/a&gt;.  12, 265-280.&lt;/p&gt;&#xA;&lt;p&gt;Sheperd, B. (2016) &lt;a href=&#34;https://www.r-econometrics.com/reproduction/2016_sheperd_gravity&#34;&gt;The gravity model of international trade: A user guide&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Timmer, M. P., Dietzenbacher, E., Los, B., Stehrer, R., &amp;amp; de Vries, G. J. (2015). &lt;a href=&#34;https://www.r-econometrics.com/reproduction/2015_timmer_wiod&#34;&gt;An Illustrated User Guide to the World Input–Output Database: the Case of Global Automotive Production&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Wooldridge, J. M. (2013) &lt;a href=&#34;https://www.r-econometrics.com/reproduction/wooldridge/wooldridgeintro&#34;&gt;Introductory econometrics&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chapter 2: Simple OLS</title>
      <link>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge02/</link>
      <pubDate>Thu, 04 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge02/</guid>
      <description>&lt;p&gt;In R the function for basic linear regression models is &lt;code&gt;lm&lt;/code&gt;, which is short for &lt;em&gt;linear model&lt;/em&gt;. Its first argument is a formula of the regression model, which has the form &lt;code&gt;y ~ a&lt;/code&gt;. The tilde between &lt;em&gt;y&lt;/em&gt; and &lt;em&gt;a&lt;/em&gt; indicates that &lt;em&gt;y&lt;/em&gt; is the dependent variable and &lt;em&gt;a&lt;/em&gt; is the explanatory variable. It is also possible to add a further explanatory variable - for example &lt;em&gt;b&lt;/em&gt; - to the regression by adding a plus sign followed by the the name of the additional variable to the formula. In our example this would result in &lt;code&gt;y ~ a + b&lt;/code&gt;. But since this chapter only covers models with a single explanatory variable, we postpone this issue to the next chapter.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chapter 5: OLS Asymptotics</title>
      <link>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge05/</link>
      <pubDate>Thu, 04 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge05/</guid>
      <description>&lt;p&gt;Make a histogram of the variable “prate”.&lt;/p&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;k401k&amp;quot;)&#xA;&#xA;hist(k401k$prate)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://www.r-econometrics.com/reproduction/wooldridge/wooldridge05_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Example 5.2&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;bwght&amp;quot;)&#xA;&#xA;lm.1 &amp;lt;- lm(lbwght ~ cigs + lfaminc, data = bwght[1:694,])&#xA;s.1 &amp;lt;- summary(lm.1)&#xA;&#xA;lm.2 &amp;lt;- lm(lbwght ~ cigs + lfaminc, data = bwght)&#xA;s.2 &amp;lt;- summary(lm.2)&#xA;&#xA;s.2$coefficients[2, 2] / s.1$coefficients[2, 2]&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## [1] 0.6443341&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm.3 &amp;lt;- lm(cigs ~ lfaminc, data = bwght[1:694,])&#xA;s.3 &amp;lt;- summary(lm.3)&#xA;&#xA;sigma.j &amp;lt;- s.3$coefficients[2, 2]&#xA;sigma &amp;lt;- s.3$sigma&#xA;r2 &amp;lt;- s.3$r.squared&#xA;sigma / (sqrt(1388) * sigma.j * sqrt(1 - r2))&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## [1] 0.6609623&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;strong&gt;Example 5.3&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Wooldridge (2013): Introductory Econometrics</title>
      <link>https://www.r-econometrics.com/reproduction/wooldridge/wooldridgeintro/</link>
      <pubDate>Thu, 04 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/wooldridge/wooldridgeintro/</guid>
      <description>&lt;p&gt;This section is based on Wooldridge, J.M. (2013). Introductory econometrics: A modern approach (5&lt;sup&gt;th&lt;/sup&gt;ed.). The following links contain examples in the main text of the book and use R to estimate the models. Alternatively, &lt;a href=&#34;http://urfie.net/&#34; target=&#34;_blank&#34;&gt;Heiss, F. (2016) Using R for Introductory Econometrics&lt;/a&gt; is a standalone textbook, which covers the same topics as Wooldridge (2013) and provides an introduction to R as well.&lt;/p&gt;&#xA;&lt;p&gt;The data sets are from the &lt;em&gt;wooldridge&lt;/em&gt; package, which is a collection of all data sets used in the Wooldridge textbook. Similar to my page, the package also has a &lt;a href=&#34;https://cran.r-project.org/web/packages/wooldridge/vignettes/Introductory-Econometrics-Examples.html&#34; target=&#34;_blank&#34;&gt;vignette&lt;/a&gt; which contains a comprehensive collection of the Wooldridge textbook examples.&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Introduction to Vector Autoregression (VAR)</title>
      <link>https://www.r-econometrics.com/timeseries/varintro/</link>
      <pubDate>Fri, 31 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/timeseries/varintro/</guid>
      <description>&lt;p&gt;Since the seminal paper of Sims (1980) vector autoregressive models have become a key instrument in macroeconomic research. This post presents the basic concept of VAR analysis and guides through the estimation procedure of a simple model. When I started my undergraduate program in economics I occasionally encountered the abbreviation &lt;em&gt;VAR&lt;/em&gt; in some macro papers. I was fascinated by those waves in the boxes titled &lt;em&gt;impulse responses&lt;/em&gt; and wondered how difficult it would be to do such reseach on my own. I was motivated, but my first attempts were admittedly embarrassing. It took me quite a long time to figure out which kind of data can be analysed, how to estimate a VAR model and how to obtain meaningful impulse responses. Today, I think that there is nothing fancy about VAR models at all once you keep in mind some points.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Time Series Topics</title>
      <link>https://www.r-econometrics.com/timeseriesintro/</link>
      <pubDate>Sat, 04 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/timeseriesintro/</guid>
      <description>&lt;p&gt;&lt;em&gt;Work in progress (September 2023). I will try to update this page over the next few months.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;This section is intended to provide an overview of the relevant issues in (macro)economic time series analysis. Again the standard disclaimer: This site does not replace a good textbook, but it should help you to get a grasp of the basic concepts more quickly than if you learned it on your own.&lt;/p&gt;&#xA;&lt;p&gt;The intended structure of this site is:&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Structure of R</title>
      <link>https://www.r-econometrics.com/rbasics/rstructure/</link>
      <pubDate>Fri, 20 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/rbasics/rstructure/</guid>
      <description>&lt;p&gt;R – just like many other standard programming languages like C, C++, Python etc. – can be comprehended as a language that provides the basis for a system of code chunks, which have been developed by many people across the globe, who wanted to share their work. Within the R community these chunks of R code are called &lt;em&gt;packages&lt;/em&gt;. And each of those packages usually consist of at least one &lt;em&gt;function&lt;/em&gt;.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; This structure is presented in the following graph. Beside a schematic description of a package and its functions in the upper part of the graph it also contains some real world examples using the packages &lt;code&gt;ggplot2&lt;/code&gt; and &lt;code&gt;dplyr&lt;/code&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Reproduction: Cincera, M. (1997). Patents, R&amp;D, and technological spillovers at the firm level.</title>
      <link>https://www.r-econometrics.com/reproduction/1997_cincera_patents/</link>
      <pubDate>Tue, 08 May 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/1997_cincera_patents/</guid>
      <description>&lt;div id=&#34;get-the-data&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Get the data&lt;/h2&gt;&#xA;&lt;p&gt;The data set can be downloaded from the &lt;a href=&#34;http://qed.econ.queensu.ca/jae/1997-v12.3/cincera/&#34; target=&#34;_blank&#34;&gt;Journal of Applied Econometrics Data Archive&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;download.file(&amp;quot;http://qed.econ.queensu.ca/jae/1997-v12.3/cincera/mc-data.zip&amp;quot;, destfile = &amp;quot;1997_cincera_data.zip&amp;quot;)&#xA;unzip(&amp;quot;1997_cincera_data.zip&amp;quot;)&#xA;&#xA;data &amp;lt;- read.delim(&amp;quot;data.mc&amp;quot;, header = FALSE)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;names(data) &amp;lt;- c(&amp;quot;fi&amp;quot;, &amp;quot;s&amp;quot;, &amp;quot;g&amp;quot;,&#xA;                 &amp;quot;p83&amp;quot;, &amp;quot;p84&amp;quot;, &amp;quot;p85&amp;quot;, &amp;quot;p86&amp;quot;, &amp;quot;p87&amp;quot;, &amp;quot;p88&amp;quot;, &amp;quot;p89&amp;quot;, &amp;quot;p90&amp;quot;, &amp;quot;p91&amp;quot;,&#xA;                 &amp;quot;lr83&amp;quot;, &amp;quot;lr84&amp;quot;, &amp;quot;lr85&amp;quot;, &amp;quot;lr86&amp;quot;, &amp;quot;lr87&amp;quot;, &amp;quot;lr88&amp;quot;, &amp;quot;lr89&amp;quot;, &amp;quot;lr90&amp;quot;, &amp;quot;lr91&amp;quot;,&#xA;                 &amp;quot;ls83&amp;quot;, &amp;quot;ls84&amp;quot;, &amp;quot;ls85&amp;quot;, &amp;quot;ls86&amp;quot;, &amp;quot;ls87&amp;quot;, &amp;quot;ls88&amp;quot;, &amp;quot;ls89&amp;quot;, &amp;quot;ls90&amp;quot;, &amp;quot;ls91&amp;quot;)&#xA;&#xA;p &amp;lt;- matrix(as.matrix(data[, c(&amp;quot;p83&amp;quot;, &amp;quot;p84&amp;quot;, &amp;quot;p85&amp;quot;, &amp;quot;p86&amp;quot;, &amp;quot;p87&amp;quot;, &amp;quot;p88&amp;quot;, &amp;quot;p89&amp;quot;, &amp;quot;p90&amp;quot;, &amp;quot;p91&amp;quot;)]))&#xA;k &amp;lt;- matrix(as.matrix(data[, c(&amp;quot;lr83&amp;quot;, &amp;quot;lr84&amp;quot;, &amp;quot;lr85&amp;quot;, &amp;quot;lr86&amp;quot;, &amp;quot;lr87&amp;quot;, &amp;quot;lr88&amp;quot;, &amp;quot;lr89&amp;quot;, &amp;quot;lr90&amp;quot;, &amp;quot;lr91&amp;quot;)]))&#xA;spill &amp;lt;- matrix(as.matrix(data[, c(&amp;quot;ls83&amp;quot;, &amp;quot;ls84&amp;quot;, &amp;quot;ls85&amp;quot;, &amp;quot;ls86&amp;quot;, &amp;quot;ls87&amp;quot;, &amp;quot;ls88&amp;quot;, &amp;quot;ls89&amp;quot;, &amp;quot;ls90&amp;quot;, &amp;quot;ls91&amp;quot;)]))&#xA;&#xA;# Firm IDs&#xA;fi &amp;lt;- rep(1:181, 9)&#xA;&#xA;# Years&#xA;year &amp;lt;- c()&#xA;for (i in 1983:1991){&#xA;  year &amp;lt;- append(year, rep(i, 181))&#xA;}&#xA; &#xA;# Geographic dummies&#xA;g &amp;lt;- rep(data$g, 9)&#xA;&#xA;g.1 &amp;lt;- as.numeric(g == 1)&#xA;g.2 &amp;lt;- as.numeric(g == 2)&#xA;g.3 &amp;lt;- as.numeric(g == 3)&#xA;g.4 &amp;lt;- as.numeric(g == 4)&#xA; &#xA;# Technological dummies&#xA;s &amp;lt;- rep(data$s, 9)&#xA; &#xA;s.1 &amp;lt;- as.numeric(s == 1)&#xA;s.2 &amp;lt;- as.numeric(s == 2)&#xA;s.3 &amp;lt;- as.numeric(s == 3)&#xA;s.4 &amp;lt;- as.numeric(s == 4)&#xA;s.5 &amp;lt;- as.numeric(s == 5)&#xA;s.6 &amp;lt;- as.numeric(s == 6)&#xA;s.7 &amp;lt;- as.numeric(s == 7)&#xA;s.8 &amp;lt;- as.numeric(s == 8)&#xA;s.9 &amp;lt;- as.numeric(s == 9)&#xA;s.10 &amp;lt;- as.numeric(s == 10)&#xA;s.11 &amp;lt;- as.numeric(s == 11)&#xA;s.12 &amp;lt;- as.numeric(s == 12)&#xA;s.13 &amp;lt;- as.numeric(s == 13)&#xA;s.14 &amp;lt;- as.numeric(s == 14)&#xA;s.15 &amp;lt;- as.numeric(s == 15)&#xA; &#xA;# Lags of R&amp;amp;D Spending&#xA;k.1 &amp;lt;- as.vector(c(rep(NA, 181), k[1:(length(k) - 181)]))&#xA;k.2 &amp;lt;- as.vector(c(rep(NA, 2 * 181), k[1:(length(k) - 2 * 181)]))&#xA;k.3 &amp;lt;- as.vector(c(rep(NA, 3 * 181), k[1:(length(k) - 3 * 181)]))&#xA;k.4 &amp;lt;- as.vector(c(rep(NA, 4 * 181), k[1:(length(k) - 4 * 181)]))&#xA; &#xA;# Lags of spillovers&#xA;spill.1 &amp;lt;- as.vector(c(rep(NA, 181), spill[1:(length(spill) - 181)]))&#xA;spill.2 &amp;lt;- as.vector(c(rep(NA, 2 * 181), spill[1:(length(spill) - 2 * 181)]))&#xA;spill.3 &amp;lt;- as.vector(c(rep(NA, 3 * 181), spill[1:(length(spill) - 3 * 181)]))&#xA;spill.4 &amp;lt;- as.vector(c(rep(NA, 4 * 181), spill[1:(length(spill) - 4 * 181)]))&#xA; &#xA;# Generate the finale data frame&#xA;data &amp;lt;- data.frame(year, fi, p, k, k.1, k.2, k.3, k.4, spill, spill.1, spill.2, spill.3, spill.4,&#xA;                   g.1, g.2, g.3, g.4, s.1, s.2, s.3, s.4, s.5, s.6, s.7, s.8, s.9, s.10,&#xA;                   s.11, s.12, s.13, s.14, s.15)&#xA; &#xA;# Give labels to the variables&#xA;attributes(data)$var.labels &amp;lt;-c(&amp;#39;Year&amp;#39;,&amp;#39;FirmID&amp;#39;,&amp;#39;# of patents&amp;#39;,&amp;#39;R&amp;amp;D spending&amp;#39;,&amp;#39;Lag R&amp;amp;D 1&amp;#39;,&#xA;                               &amp;#39;Lag R&amp;amp;D 2&amp;#39;,&amp;#39;Lag R&amp;amp;D 3&amp;#39;,&amp;#39;Lag R&amp;amp;D 4&amp;#39;,&amp;#39;Spillover&amp;#39;,&amp;#39;Lag spillover 1&amp;#39;,&#xA;                               &amp;#39;Lag spillover 2&amp;#39;,&amp;#39;Lag spillover 3&amp;#39;,&amp;#39;Lag spillover 4&amp;#39;,&#xA;                               &amp;#39;Geographic dummy 1&amp;#39;,&amp;#39;Geographic dummy 2&amp;#39;,&amp;#39;Geographic dummy 3&amp;#39;,&#xA;                               &amp;#39;Geographic dummy 4&amp;#39;,&amp;#39;Sector dummy 1&amp;#39;,&amp;#39;Sector dummy 2&amp;#39;,&#xA;                               &amp;#39;Sector dummy 3&amp;#39;,&amp;#39;Sector dummy 4&amp;#39;,&amp;#39;Sector dummy 5&amp;#39;,&#xA;                               &amp;#39;Sector dummy 6&amp;#39;,&amp;#39;Sector dummy 7&amp;#39;,&amp;#39;Sector dummy 8&amp;#39;,&#xA;                               &amp;#39;Sector dummy 9&amp;#39;,&amp;#39;Sector dummy 10&amp;#39;,&amp;#39;Sector dummy 11&amp;#39;,&#xA;                               &amp;#39;Sector dummy 12&amp;#39;,&amp;#39;Sector dummy 13&amp;#39;,&amp;#39;Sector dummy 14&amp;#39;,&#xA;                               &amp;#39;Sector dummy 15&amp;#39;)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;If you want, you can save the modified data on your disk:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chapter 14: Advanced Panel Data Methods</title>
      <link>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge14/</link>
      <pubDate>Tue, 06 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge14/</guid>
      <description>&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(wooldridge)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;In order to estimate panel data models, I use the &lt;code&gt;plm&lt;/code&gt; function from the &lt;code&gt;plm&lt;/code&gt; package. The intuition behind its structure is similar to the ordinary linear model, except that it allows you to specify the panel’s group and time variables and the effects model.&lt;/p&gt;&#xA;&lt;div id=&#34;example-14.1&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Example 14.1&lt;/h3&gt;&#xA;&lt;p&gt;Similar to the &lt;code&gt;lm&lt;/code&gt; function, you can specify your model’s equation and the sample. Since you want to use panel data methods for you estimation, you also have to specify which variables in your sample contain the information used to distinguish different groups and which variable contains the time measurement. In our example this is done with &lt;code&gt;index = c(&amp;quot;fcode&amp;quot;, &amp;quot;year&amp;quot;)&lt;/code&gt;. Note, that the order of the variables is important. The group variable always has to be at the first and the time variable at the second position.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chapter 15: Instrumental Variables Estimation and Two Stage Least Squares</title>
      <link>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge15/</link>
      <pubDate>Tue, 06 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge15/</guid>
      <description>&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(AER)&#xA;library(wooldridge)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;div id=&#34;example-15.1&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Example 15.1&lt;/h3&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;mroz&amp;quot;)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;OLS&lt;/p&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s.lm.1 &amp;lt;- summary(lm(lwage ~ educ, data = mroz))&#xA;s.lm.1&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = lwage ~ educ, data = mroz)&#xA;## &#xA;## Residuals:&#xA;##      Min       1Q   Median       3Q      Max &#xA;## -3.10256 -0.31473  0.06434  0.40081  2.10029 &#xA;## &#xA;## Coefficients:&#xA;##             Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)  -0.1852     0.1852  -1.000    0.318    &#xA;## educ          0.1086     0.0144   7.545 2.76e-13 ***&#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 0.68 on 426 degrees of freedom&#xA;##   (325 observations deleted due to missingness)&#xA;## Multiple R-squared:  0.1179, Adjusted R-squared:  0.1158 &#xA;## F-statistic: 56.93 on 1 and 426 DF,  p-value: 2.761e-13&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;em&gt;fatheduc&lt;/em&gt; as IV for &lt;em&gt;educ&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chapter13: Simple Panel Data Methods</title>
      <link>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge13/</link>
      <pubDate>Mon, 05 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge13/</guid>
      <description>&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(wooldridge)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;div id=&#34;example-13.1&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Example 13.1&lt;/h3&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;fertil1&amp;quot;)&#xA;&#xA;s.lm.1 &amp;lt;- summary(lm.1 &amp;lt;- lm(kids ~ educ + age + agesq + black + east + northcen + west +&#xA;                          farm + othrural + town + smcity +&#xA;                          y74 + y76 + y78 + y80 + y82 + y84, data = fertil1))&#xA;&#xA;s.lm.1&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = kids ~ educ + age + agesq + black + east + northcen + &#xA;##     west + farm + othrural + town + smcity + y74 + y76 + y78 + &#xA;##     y80 + y82 + y84, data = fertil1)&#xA;## &#xA;## Residuals:&#xA;##     Min      1Q  Median      3Q     Max &#xA;## -3.9878 -1.0086 -0.0767  0.9331  4.6548 &#xA;## &#xA;## Coefficients:&#xA;##              Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept) -7.742457   3.051767  -2.537 0.011315 *  &#xA;## educ        -0.128427   0.018349  -6.999 4.44e-12 ***&#xA;## age          0.532135   0.138386   3.845 0.000127 ***&#xA;## agesq       -0.005804   0.001564  -3.710 0.000217 ***&#xA;## black        1.075658   0.173536   6.198 8.02e-10 ***&#xA;## east         0.217324   0.132788   1.637 0.101992    &#xA;## northcen     0.363114   0.120897   3.004 0.002729 ** &#xA;## west         0.197603   0.166913   1.184 0.236719    &#xA;## farm        -0.052557   0.147190  -0.357 0.721105    &#xA;## othrural    -0.162854   0.175442  -0.928 0.353481    &#xA;## town         0.084353   0.124531   0.677 0.498314    &#xA;## smcity       0.211879   0.160296   1.322 0.186507    &#xA;## y74          0.268183   0.172716   1.553 0.120771    &#xA;## y76         -0.097379   0.179046  -0.544 0.586633    &#xA;## y78         -0.068666   0.181684  -0.378 0.705544    &#xA;## y80         -0.071305   0.182771  -0.390 0.696511    &#xA;## y82         -0.522484   0.172436  -3.030 0.002502 ** &#xA;## y84         -0.545166   0.174516  -3.124 0.001831 ** &#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 1.555 on 1111 degrees of freedom&#xA;## Multiple R-squared:  0.1295, Adjusted R-squared:  0.1162 &#xA;## F-statistic: 9.723 on 17 and 1111 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s.lm.2 &amp;lt;- summary(lm.2 &amp;lt;- lm(kids ~ educ + age + agesq + black + east + northcen + west +&#xA;                          farm + othrural + town + smcity,data = fertil1))&#xA;&#xA;anova(lm.1, lm.2)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table&#xA;## &#xA;## Model 1: kids ~ educ + age + agesq + black + east + northcen + west + &#xA;##     farm + othrural + town + smcity + y74 + y76 + y78 + y80 + &#xA;##     y82 + y84&#xA;## Model 2: kids ~ educ + age + agesq + black + east + northcen + west + &#xA;##     farm + othrural + town + smcity&#xA;##   Res.Df    RSS Df Sum of Sq      F    Pr(&amp;gt;F)    &#xA;## 1   1111 2685.9                                  &#xA;## 2   1117 2771.0 -6   -85.139 5.8695 4.855e-06 ***&#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div id=&#34;example-13.2&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Example 13.2&lt;/h3&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;cps78_85&amp;quot;)&#xA;&#xA;s.lm.1 &amp;lt;- summary(lm.1 &amp;lt;- lm(lwage ~ y85 + educ + y85educ + exper + expersq +&#xA;                               union + female + y85fem, data = cps78_85))&#xA;&#xA;s.lm.1&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = lwage ~ y85 + educ + y85educ + exper + expersq + &#xA;##     union + female + y85fem, data = cps78_85)&#xA;## &#xA;## Residuals:&#xA;##      Min       1Q   Median       3Q      Max &#xA;## -2.56098 -0.25828  0.00864  0.26571  2.11669 &#xA;## &#xA;## Coefficients:&#xA;##               Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)  4.589e-01  9.345e-02   4.911 1.05e-06 ***&#xA;## y85          1.178e-01  1.238e-01   0.952   0.3415    &#xA;## educ         7.472e-02  6.676e-03  11.192  &amp;lt; 2e-16 ***&#xA;## y85educ      1.846e-02  9.354e-03   1.974   0.0487 *  &#xA;## exper        2.958e-02  3.567e-03   8.293 3.27e-16 ***&#xA;## expersq     -3.994e-04  7.754e-05  -5.151 3.08e-07 ***&#xA;## union        2.021e-01  3.029e-02   6.672 4.03e-11 ***&#xA;## female      -3.167e-01  3.662e-02  -8.648  &amp;lt; 2e-16 ***&#xA;## y85fem       8.505e-02  5.131e-02   1.658   0.0977 .  &#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 0.4127 on 1075 degrees of freedom&#xA;## Multiple R-squared:  0.4262, Adjusted R-squared:  0.4219 &#xA;## F-statistic:  99.8 on 8 and 1075 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div id=&#34;example-13.3&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Example 13.3&lt;/h3&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;kielmc&amp;quot;)&#xA;&#xA;s.lm.1 &amp;lt;- summary(lm.1 &amp;lt;- lm(rprice ~ nearinc, data = kielmc[kielmc$year==1981,]))&#xA;s.lm.1&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = rprice ~ nearinc, data = kielmc[kielmc$year == 1981, &#xA;##     ])&#xA;## &#xA;## Residuals:&#xA;##    Min     1Q Median     3Q    Max &#xA;## -60678 -19832  -2997  21139 136754 &#xA;## &#xA;## Coefficients:&#xA;##             Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)   101308       3093  32.754  &amp;lt; 2e-16 ***&#xA;## nearinc       -30688       5828  -5.266 5.14e-07 ***&#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 31240 on 140 degrees of freedom&#xA;## Multiple R-squared:  0.1653, Adjusted R-squared:  0.1594 &#xA;## F-statistic: 27.73 on 1 and 140 DF,  p-value: 5.139e-07&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s.lm.2 &amp;lt;- summary(lm.2 &amp;lt;- lm(rprice ~ nearinc, data = kielmc[kielmc$year == 1978,]))&#xA;s.lm.2&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = rprice ~ nearinc, data = kielmc[kielmc$year == 1978, &#xA;##     ])&#xA;## &#xA;## Residuals:&#xA;##    Min     1Q Median     3Q    Max &#xA;## -56517 -16605  -3193   8683 236307 &#xA;## &#xA;## Coefficients:&#xA;##             Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)    82517       2654  31.094  &amp;lt; 2e-16 ***&#xA;## nearinc       -18824       4745  -3.968 0.000105 ***&#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 29430 on 177 degrees of freedom&#xA;## Multiple R-squared:  0.08167,    Adjusted R-squared:  0.07648 &#xA;## F-statistic: 15.74 on 1 and 177 DF,  p-value: 0.0001054&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s.lm.3.1 &amp;lt;- summary(lm.3.1 &amp;lt;- lm(rprice ~ y81 + nearinc + y81nrinc, data = kielmc))&#xA;s.lm.3.1&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = rprice ~ y81 + nearinc + y81nrinc, data = kielmc)&#xA;## &#xA;## Residuals:&#xA;##    Min     1Q Median     3Q    Max &#xA;## -60678 -17693  -3031  12483 236307 &#xA;## &#xA;## Coefficients:&#xA;##             Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)    82517       2727  30.260  &amp;lt; 2e-16 ***&#xA;## y81            18790       4050   4.640 5.12e-06 ***&#xA;## nearinc       -18824       4875  -3.861 0.000137 ***&#xA;## y81nrinc      -11864       7457  -1.591 0.112595    &#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 30240 on 317 degrees of freedom&#xA;## Multiple R-squared:  0.1739, Adjusted R-squared:  0.1661 &#xA;## F-statistic: 22.25 on 3 and 317 DF,  p-value: 4.224e-13&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s.lm.3.2 &amp;lt;- summary(lm.3.2 &amp;lt;- lm(rprice ~ y81 + nearinc + y81nrinc + age + agesq, data = kielmc))&#xA;s.lm.3.2&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = rprice ~ y81 + nearinc + y81nrinc + age + agesq, &#xA;##     data = kielmc)&#xA;## &#xA;## Residuals:&#xA;##    Min     1Q Median     3Q    Max &#xA;## -79349 -14431  -1711  10069 201486 &#xA;## &#xA;## Coefficients:&#xA;##               Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)  8.912e+04  2.406e+03  37.039  &amp;lt; 2e-16 ***&#xA;## y81          2.132e+04  3.444e+03   6.191 1.86e-09 ***&#xA;## nearinc      9.398e+03  4.812e+03   1.953 0.051713 .  &#xA;## y81nrinc    -2.192e+04  6.360e+03  -3.447 0.000644 ***&#xA;## age         -1.494e+03  1.319e+02 -11.333  &amp;lt; 2e-16 ***&#xA;## agesq        8.691e+00  8.481e-01  10.248  &amp;lt; 2e-16 ***&#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 25540 on 315 degrees of freedom&#xA;## Multiple R-squared:  0.4144, Adjusted R-squared:  0.4052 &#xA;## F-statistic: 44.59 on 5 and 315 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s.lm.3.3 &amp;lt;- summary(lm.3.3 &amp;lt;- lm(rprice ~ y81 + nearinc + y81nrinc + age + agesq +&#xA;                                   intst + land + area + rooms + baths, data = kielmc))&#xA;s.lm.3.3&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = rprice ~ y81 + nearinc + y81nrinc + age + agesq + &#xA;##     intst + land + area + rooms + baths, data = kielmc)&#xA;## &#xA;## Residuals:&#xA;##    Min     1Q Median     3Q    Max &#xA;## -76721  -8885   -252   8433 136649 &#xA;## &#xA;## Coefficients:&#xA;##               Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)  1.381e+04  1.117e+04   1.237  0.21720    &#xA;## y81          1.393e+04  2.799e+03   4.977 1.07e-06 ***&#xA;## nearinc      3.780e+03  4.453e+03   0.849  0.39661    &#xA;## y81nrinc    -1.418e+04  4.987e+03  -2.843  0.00477 ** &#xA;## age         -7.395e+02  1.311e+02  -5.639 3.85e-08 ***&#xA;## agesq        3.453e+00  8.128e-01   4.248 2.86e-05 ***&#xA;## intst       -5.386e-01  1.963e-01  -2.743  0.00643 ** &#xA;## land         1.414e-01  3.108e-02   4.551 7.69e-06 ***&#xA;## area         1.809e+01  2.306e+00   7.843 7.16e-14 ***&#xA;## rooms        3.304e+03  1.661e+03   1.989  0.04758 *  &#xA;## baths        6.977e+03  2.581e+03   2.703  0.00725 ** &#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 19620 on 310 degrees of freedom&#xA;## Multiple R-squared:   0.66,  Adjusted R-squared:  0.6491 &#xA;## F-statistic: 60.19 on 10 and 310 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s.lm.4.1 &amp;lt;- summary(lm.4.1 &amp;lt;- lm(lprice ~ y81 + nearinc + y81nrinc, data = kielmc))&#xA;s.lm.4.1&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = lprice ~ y81 + nearinc + y81nrinc, data = kielmc)&#xA;## &#xA;## Residuals:&#xA;##      Min       1Q   Median       3Q      Max &#xA;## -1.11957 -0.20328  0.02226  0.18909  1.66604 &#xA;## &#xA;## Coefficients:&#xA;##             Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept) 11.28542    0.03051 369.839  &amp;lt; 2e-16 ***&#xA;## y81          0.45700    0.04532  10.084  &amp;lt; 2e-16 ***&#xA;## nearinc     -0.33992    0.05456  -6.231 1.48e-09 ***&#xA;## y81nrinc    -0.06265    0.08344  -0.751    0.453    &#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 0.3384 on 317 degrees of freedom&#xA;## Multiple R-squared:  0.4091, Adjusted R-squared:  0.4035 &#xA;## F-statistic: 73.15 on 3 and 317 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s.lm.4.2 &amp;lt;- summary(lm.4.2 &amp;lt;- lm(lrprice ~ y81 + nearinc + y81nrinc + age + agesq + &#xA;                                   lintst + lland + larea + rooms + baths, data = kielmc))&#xA;s.lm.4.2&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = lrprice ~ y81 + nearinc + y81nrinc + age + agesq + &#xA;##     lintst + lland + larea + rooms + baths, data = kielmc)&#xA;## &#xA;## Residuals:&#xA;##      Min       1Q   Median       3Q      Max &#xA;## -1.18441 -0.09947  0.01478  0.10985  0.74872 &#xA;## &#xA;## Coefficients:&#xA;##               Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)  7.652e+00  4.159e-01  18.399  &amp;lt; 2e-16 ***&#xA;## y81          1.621e-01  2.850e-02   5.687 2.99e-08 ***&#xA;## nearinc      3.223e-02  4.749e-02   0.679 0.497805    &#xA;## y81nrinc    -1.315e-01  5.197e-02  -2.531 0.011885 *  &#xA;## age         -8.359e-03  1.411e-03  -5.924 8.36e-09 ***&#xA;## agesq        3.764e-05  8.668e-06   4.342 1.92e-05 ***&#xA;## lintst      -6.145e-02  3.151e-02  -1.950 0.052045 .  &#xA;## lland        9.985e-02  2.449e-02   4.077 5.81e-05 ***&#xA;## larea        3.508e-01  5.149e-02   6.813 4.98e-11 ***&#xA;## rooms        4.733e-02  1.733e-02   2.732 0.006661 ** &#xA;## baths        9.428e-02  2.773e-02   3.400 0.000761 ***&#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 0.2038 on 310 degrees of freedom&#xA;## Multiple R-squared:  0.7326, Adjusted R-squared:  0.7239 &#xA;## F-statistic: 84.92 on 10 and 310 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div id=&#34;example-13.4&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Example 13.4&lt;/h3&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;injury&amp;quot;)&#xA;&#xA;s.lm.1 &amp;lt;- summary(lm.1 &amp;lt;- lm(ldurat ~ afchnge + highearn + afhigh, data = injury))&#xA;s.lm.1&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = ldurat ~ afchnge + highearn + afhigh, data = injury)&#xA;## &#xA;## Residuals:&#xA;##     Min      1Q  Median      3Q     Max &#xA;## -3.0128 -0.7214 -0.0171  0.7714  4.0047 &#xA;## &#xA;## Coefficients:&#xA;##             Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)  1.19934    0.02711  44.241  &amp;lt; 2e-16 ***&#xA;## afchnge      0.02364    0.03970   0.595  0.55164    &#xA;## highearn     0.21520    0.04336   4.963 7.11e-07 ***&#xA;## afhigh       0.18835    0.06279   2.999  0.00271 ** &#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 1.298 on 7146 degrees of freedom&#xA;## Multiple R-squared:  0.01584,    Adjusted R-squared:  0.01543 &#xA;## F-statistic: 38.34 on 3 and 7146 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Hmmm, more observations in this estimation and the results differ…&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chapter 3: Multiple Regression Analysis</title>
      <link>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge03/</link>
      <pubDate>Sun, 04 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge03/</guid>
      <description>&lt;p&gt;Below you find the script for all examples in chapter 3 of Wooldridge (2013). The only difference to the last chapter is how to use multiple independent variables in the &lt;code&gt;lm&lt;/code&gt; function. This is easily achieved by separating each exogenous variable that should enter the model with a plus sign, e.g. &lt;code&gt;lm(colGPA ~ hsGPA + ACT)&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;p&gt;The other commands that appear new are quite helpful and you should take a minute to think about them:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chapter 6: Further Issues</title>
      <link>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge06/</link>
      <pubDate>Sun, 04 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge06/</guid>
      <description>&lt;p&gt;Chapter 6 in Wooldridge (2013) deals with some more issues that might have an impact on your estimates. Among these are a change in the scale of your variables, so-called beta-factors and the interpretation of variables that appear together with their squared values, i.e. interaction terms.&lt;/p&gt;&#xA;&lt;p&gt;Before you start, set your working directory, load the &lt;code&gt;foreign&lt;/code&gt; library and download the data we are going to use in this chapter.&lt;/p&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(QuantPsyc)&#xA;library(wooldridge)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;strong&gt;The impact of scales on the estimated coefficients&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chapter 7: Multiple Regression Analysis with Qualitative Information</title>
      <link>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge07/</link>
      <pubDate>Sun, 04 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge07/</guid>
      <description>&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(wooldridge)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Estimating dummy variables that reflect qualitative information works quite the same way in R as it does with quantitative variables. You just add it as an independent variable into the formula of the model.&lt;/p&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Example 7.1&#xA;data(&amp;quot;wage1&amp;quot;)&#xA;&#xA;lm.7.1.1 &amp;lt;- lm(wage ~ female + educ + exper + tenure, data = wage1)&#xA;summary(lm.7.1.1)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = wage ~ female + educ + exper + tenure, data = wage1)&#xA;## &#xA;## Residuals:&#xA;##     Min      1Q  Median      3Q     Max &#xA;## -7.7675 -1.8080 -0.4229  1.0467 14.0075 &#xA;## &#xA;## Coefficients:&#xA;##             Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept) -1.56794    0.72455  -2.164   0.0309 *  &#xA;## female      -1.81085    0.26483  -6.838 2.26e-11 ***&#xA;## educ         0.57150    0.04934  11.584  &amp;lt; 2e-16 ***&#xA;## exper        0.02540    0.01157   2.195   0.0286 *  &#xA;## tenure       0.14101    0.02116   6.663 6.83e-11 ***&#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 2.958 on 521 degrees of freedom&#xA;## Multiple R-squared:  0.3635, Adjusted R-squared:  0.3587 &#xA;## F-statistic:  74.4 on 4 and 521 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm.7.1.2 &amp;lt;- lm(wage ~ female, data = wage1)&#xA;summary(lm.7.1.2)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = wage ~ female, data = wage1)&#xA;## &#xA;## Residuals:&#xA;##     Min      1Q  Median      3Q     Max &#xA;## -5.5995 -1.8495 -0.9877  1.4260 17.8805 &#xA;## &#xA;## Coefficients:&#xA;##             Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)   7.0995     0.2100  33.806  &amp;lt; 2e-16 ***&#xA;## female       -2.5118     0.3034  -8.279 1.04e-15 ***&#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 3.476 on 524 degrees of freedom&#xA;## Multiple R-squared:  0.1157, Adjusted R-squared:  0.114 &#xA;## F-statistic: 68.54 on 1 and 524 DF,  p-value: 1.042e-15&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Example 7.2&#xA;data(&amp;quot;gpa1&amp;quot;)&#xA;&#xA;lm.7.2 &amp;lt;- lm(colGPA ~ PC + hsGPA + ACT, data = gpa1)&#xA;summary(lm.7.2)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = colGPA ~ PC + hsGPA + ACT, data = gpa1)&#xA;## &#xA;## Residuals:&#xA;##     Min      1Q  Median      3Q     Max &#xA;## -0.7901 -0.2622 -0.0107  0.2334  0.7570 &#xA;## &#xA;## Coefficients:&#xA;##             Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept) 1.263520   0.333125   3.793 0.000223 ***&#xA;## PC          0.157309   0.057287   2.746 0.006844 ** &#xA;## hsGPA       0.447242   0.093647   4.776 4.54e-06 ***&#xA;## ACT         0.008659   0.010534   0.822 0.412513    &#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 0.3325 on 137 degrees of freedom&#xA;## Multiple R-squared:  0.2194, Adjusted R-squared:  0.2023 &#xA;## F-statistic: 12.83 on 3 and 137 DF,  p-value: 1.932e-07&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Example 7.3&#xA;data(&amp;quot;jtrain&amp;quot;)&#xA;  # Since we do not use the whole data, but just observations from 1988&#xA;  # we have to manipulate the sampe&#xA;jtrain &amp;lt;- jtrain[jtrain$d88==1,]&#xA;  # We choose those observation, where in each row of the sampel it holds&#xA;  # that jtrain$d88==1.&#xA;  # Then we estimate the usual regression.&#xA;lm.7.3 &amp;lt;- lm(hrsemp ~ grant + lsales + lemploy, data = jtrain)&#xA;summary(lm.7.3)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = hrsemp ~ grant + lsales + lemploy, data = jtrain)&#xA;## &#xA;## Residuals:&#xA;##     Min      1Q  Median      3Q     Max &#xA;## -36.874 -13.128  -3.642   4.770 119.618 &#xA;## &#xA;## Coefficients:&#xA;##             Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)  46.6651    43.4121   1.075    0.285    &#xA;## grant        26.2545     5.5918   4.695  8.4e-06 ***&#xA;## lsales       -0.9846     3.5399  -0.278    0.781    &#xA;## lemploy      -6.0699     3.8829  -1.563    0.121    &#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 24.38 on 101 degrees of freedom&#xA;##   (52 observations deleted due to missingness)&#xA;## Multiple R-squared:  0.2368, Adjusted R-squared:  0.2141 &#xA;## F-statistic: 10.44 on 3 and 101 DF,  p-value: 4.804e-06&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Example 7.4&#xA;data(&amp;quot;hprice1&amp;quot;)&#xA;lm.7.4 &amp;lt;- lm(lprice ~ llotsize + lsqrft + bdrms + colonial, data = hprice1)&#xA;summary(lm.7.4)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = lprice ~ llotsize + lsqrft + bdrms + colonial, data = hprice1)&#xA;## &#xA;## Residuals:&#xA;##      Min       1Q   Median       3Q      Max &#xA;## -0.69479 -0.09750 -0.01619  0.09151  0.70228 &#xA;## &#xA;## Coefficients:&#xA;##             Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept) -1.34959    0.65104  -2.073   0.0413 *  &#xA;## llotsize     0.16782    0.03818   4.395 3.25e-05 ***&#xA;## lsqrft       0.70719    0.09280   7.620 3.69e-11 ***&#xA;## bdrms        0.02683    0.02872   0.934   0.3530    &#xA;## colonial     0.05380    0.04477   1.202   0.2330    &#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 0.1841 on 83 degrees of freedom&#xA;## Multiple R-squared:  0.6491, Adjusted R-squared:  0.6322 &#xA;## F-statistic: 38.38 on 4 and 83 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Example 7.5&#xA;lm.7.5 &amp;lt;- lm(lwage ~ female + educ + exper + expersq + tenure + tenursq, data = wage1)&#xA;summary(lm.7.5)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = lwage ~ female + educ + exper + expersq + tenure + &#xA;##     tenursq, data = wage1)&#xA;## &#xA;## Residuals:&#xA;##      Min       1Q   Median       3Q      Max &#xA;## -1.83160 -0.25658 -0.02126  0.25500  1.13370 &#xA;## &#xA;## Coefficients:&#xA;##               Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)  0.4166910  0.0989279   4.212 2.98e-05 ***&#xA;## female      -0.2965110  0.0358055  -8.281 1.04e-15 ***&#xA;## educ         0.0801967  0.0067573  11.868  &amp;lt; 2e-16 ***&#xA;## exper        0.0294324  0.0049752   5.916 6.00e-09 ***&#xA;## expersq     -0.0005827  0.0001073  -5.431 8.65e-08 ***&#xA;## tenure       0.0317139  0.0068452   4.633 4.56e-06 ***&#xA;## tenursq     -0.0005852  0.0002347  -2.493    0.013 *  &#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 0.3998 on 519 degrees of freedom&#xA;## Multiple R-squared:  0.4408, Adjusted R-squared:  0.4343 &#xA;## F-statistic: 68.18 on 6 and 519 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;For the more accurate estimate extract the coefficient on female from the summary function, paste it into the &lt;code&gt;exp&lt;/code&gt; function and subract 1.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chapter 9: More on Specification and Data Issues</title>
      <link>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge09/</link>
      <pubDate>Sun, 04 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge09/</guid>
      <description>&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(wooldridge)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;div id=&#34;example-9.1&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Example 9.1&lt;/h3&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;crime1&amp;quot;)&#xA;&#xA;lm.9.1.1 &amp;lt;- lm(narr86 ~ pcnv + avgsen + tottime + ptime86 + &#xA;                 qemp86 + inc86 + black + hispan, data = crime1)&#xA;summary(lm.9.1.1)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = narr86 ~ pcnv + avgsen + tottime + ptime86 + qemp86 + &#xA;##     inc86 + black + hispan, data = crime1)&#xA;## &#xA;## Residuals:&#xA;##     Min      1Q  Median      3Q     Max &#xA;## -1.0108 -0.4518 -0.2392  0.2707 11.5284 &#xA;## &#xA;## Coefficients:&#xA;##               Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)  0.5686855  0.0360461  15.777  &amp;lt; 2e-16 ***&#xA;## pcnv        -0.1332344  0.0403502  -3.302 0.000973 ***&#xA;## avgsen      -0.0113177  0.0122401  -0.925 0.355233    &#xA;## tottime      0.0120224  0.0094352   1.274 0.202698    &#xA;## ptime86     -0.0408417  0.0088120  -4.635 3.74e-06 ***&#xA;## qemp86      -0.0505398  0.0144397  -3.500 0.000473 ***&#xA;## inc86       -0.0014887  0.0003406  -4.370 1.29e-05 ***&#xA;## black        0.3265035  0.0454156   7.189 8.38e-13 ***&#xA;## hispan       0.1939144  0.0397113   4.883 1.10e-06 ***&#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 0.8286 on 2716 degrees of freedom&#xA;## Multiple R-squared:  0.07232,    Adjusted R-squared:  0.06959 &#xA;## F-statistic: 26.47 on 8 and 2716 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Seems to be an error in the book.&#xA;# Although all coefficients and their standard errors are equal&#xA;# the intercept term is 0.569 instead of 0.596.&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm.9.1.2 &amp;lt;- lm(narr86 ~ pcnv + avgsen + tottime + ptime86 + &#xA;                 qemp86 + inc86 + black + hispan + pcnvsq + &#xA;                 pt86sq + inc86sq, data = crime1)&#xA;summary(lm.9.1.2)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = narr86 ~ pcnv + avgsen + tottime + ptime86 + qemp86 + &#xA;##     inc86 + black + hispan + pcnvsq + pt86sq + inc86sq, data = crime1)&#xA;## &#xA;## Residuals:&#xA;##     Min      1Q  Median      3Q     Max &#xA;## -1.5248 -0.4646 -0.2151  0.2276 11.4286 &#xA;## &#xA;## Coefficients:&#xA;##               Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)  5.046e-01  3.684e-02  13.699  &amp;lt; 2e-16 ***&#xA;## pcnv         5.525e-01  1.542e-01   3.582 0.000347 ***&#xA;## avgsen      -1.702e-02  1.205e-02  -1.412 0.158028    &#xA;## tottime      1.195e-02  9.282e-03   1.288 0.197924    &#xA;## ptime86      2.874e-01  4.426e-02   6.494 9.88e-11 ***&#xA;## qemp86      -1.409e-02  1.736e-02  -0.812 0.416970    &#xA;## inc86       -3.415e-03  8.037e-04  -4.249 2.22e-05 ***&#xA;## black        2.923e-01  4.483e-02   6.520 8.35e-11 ***&#xA;## hispan       1.636e-01  3.945e-02   4.147 3.47e-05 ***&#xA;## pcnvsq      -7.302e-01  1.561e-01  -4.677 3.05e-06 ***&#xA;## pt86sq      -2.961e-02  3.863e-03  -7.664 2.50e-14 ***&#xA;## inc86sq      7.186e-06  2.556e-06   2.811 0.004969 ** &#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 0.8151 on 2713 degrees of freedom&#xA;## Multiple R-squared:  0.1035, Adjusted R-squared:  0.09982 &#xA;## F-statistic: 28.46 on 11 and 2713 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anova(lm.9.1.1, lm.9.1.2)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table&#xA;## &#xA;## Model 1: narr86 ~ pcnv + avgsen + tottime + ptime86 + qemp86 + inc86 + &#xA;##     black + hispan&#xA;## Model 2: narr86 ~ pcnv + avgsen + tottime + ptime86 + qemp86 + inc86 + &#xA;##     black + hispan + pcnvsq + pt86sq + inc86sq&#xA;##   Res.Df    RSS Df Sum of Sq      F    Pr(&amp;gt;F)    &#xA;## 1   2716 1865.0                                  &#xA;## 2   2713 1802.4  3    62.589 31.404 &amp;lt; 2.2e-16 ***&#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div id=&#34;example-9.2&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Example 9.2&lt;/h3&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;hprice1&amp;quot;)&#xA;&#xA;lm.9.2.1 &amp;lt;- lm(price ~ lotsize + sqrft + bdrms, data = hprice1)&#xA;fit2.1 &amp;lt;- lm.9.2.1$fitted.values^2&#xA;fit3.1 &amp;lt;- lm.9.2.1$fitted.values^3&#xA;lm.9.2.1.reset &amp;lt;- lm(price ~ lotsize + sqrft + bdrms + fit2.1 + fit3.1, data = hprice1)&#xA;anova(lm.9.2.1, lm.9.2.1.reset)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table&#xA;## &#xA;## Model 1: price ~ lotsize + sqrft + bdrms&#xA;## Model 2: price ~ lotsize + sqrft + bdrms + fit2.1 + fit3.1&#xA;##   Res.Df    RSS Df Sum of Sq      F  Pr(&amp;gt;F)  &#xA;## 1     84 300724                              &#xA;## 2     82 269984  2     30740 4.6682 0.01202 *&#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm.9.2.2 &amp;lt;- lm(lprice ~ llotsize + lsqrft + bdrms, data = hprice1)&#xA;fit2.2 &amp;lt;- lm.9.2.2$fitted.values^2&#xA;fit3.2 &amp;lt;- lm.9.2.2$fitted.values^3&#xA;lm.9.2.2.reset &amp;lt;- lm(lprice ~ llotsize + lsqrft + bdrms + fit2.2 + fit3.2, data = hprice1)&#xA;anova(lm.9.2.2, lm.9.2.2.reset)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table&#xA;## &#xA;## Model 1: lprice ~ llotsize + lsqrft + bdrms&#xA;## Model 2: lprice ~ llotsize + lsqrft + bdrms + fit2.2 + fit3.2&#xA;##   Res.Df    RSS Df Sum of Sq     F  Pr(&amp;gt;F)  &#xA;## 1     84 2.8626                             &#xA;## 2     82 2.6940  2   0.16854 2.565 0.08308 .&#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div id=&#34;table-9.2&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Table 9.2&lt;/h3&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;wage2&amp;quot;)&#xA;&#xA;lm.t9.2.1 &amp;lt;- lm(lwage ~ educ + exper + tenure + married + south + urban + &#xA;                  black, data = wage2)&#xA;summary(lm.t9.2.1)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = lwage ~ educ + exper + tenure + married + south + &#xA;##     urban + black, data = wage2)&#xA;## &#xA;## Residuals:&#xA;##      Min       1Q   Median       3Q      Max &#xA;## -1.98069 -0.21996  0.00707  0.24288  1.22822 &#xA;## &#xA;## Coefficients:&#xA;##              Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)  5.395497   0.113225  47.653  &amp;lt; 2e-16 ***&#xA;## educ         0.065431   0.006250  10.468  &amp;lt; 2e-16 ***&#xA;## exper        0.014043   0.003185   4.409 1.16e-05 ***&#xA;## tenure       0.011747   0.002453   4.789 1.95e-06 ***&#xA;## married      0.199417   0.039050   5.107 3.98e-07 ***&#xA;## south       -0.090904   0.026249  -3.463 0.000558 ***&#xA;## urban        0.183912   0.026958   6.822 1.62e-11 ***&#xA;## black       -0.188350   0.037667  -5.000 6.84e-07 ***&#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 0.3655 on 927 degrees of freedom&#xA;## Multiple R-squared:  0.2526, Adjusted R-squared:  0.2469 &#xA;## F-statistic: 44.75 on 7 and 927 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm.t9.2.2 &amp;lt;- lm(lwage ~ educ + exper + tenure + married + south + urban + &#xA;                  black + IQ, data=wage2)&#xA;summary(lm.t9.2.2)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = lwage ~ educ + exper + tenure + married + south + &#xA;##     urban + black + IQ, data = wage2)&#xA;## &#xA;## Residuals:&#xA;##      Min       1Q   Median       3Q      Max &#xA;## -2.01203 -0.22244  0.01017  0.22951  1.27478 &#xA;## &#xA;## Coefficients:&#xA;##               Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)  5.1764392  0.1280006  40.441  &amp;lt; 2e-16 ***&#xA;## educ         0.0544106  0.0069285   7.853 1.12e-14 ***&#xA;## exper        0.0141458  0.0031651   4.469 8.82e-06 ***&#xA;## tenure       0.0113951  0.0024394   4.671 3.44e-06 ***&#xA;## married      0.1997644  0.0388025   5.148 3.21e-07 ***&#xA;## south       -0.0801695  0.0262529  -3.054 0.002325 ** &#xA;## urban        0.1819463  0.0267929   6.791 1.99e-11 ***&#xA;## black       -0.1431253  0.0394925  -3.624 0.000306 ***&#xA;## IQ           0.0035591  0.0009918   3.589 0.000350 ***&#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 0.3632 on 926 degrees of freedom&#xA;## Multiple R-squared:  0.2628, Adjusted R-squared:  0.2564 &#xA;## F-statistic: 41.27 on 8 and 926 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm.t9.2.3 &amp;lt;- lm(lwage ~ educ + exper + tenure + married + south + urban + &#xA;                black + IQ + IQ*educ, data = wage2)&#xA;summary(lm.t9.2.3)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = lwage ~ educ + exper + tenure + married + south + &#xA;##     urban + black + IQ + IQ * educ, data = wage2)&#xA;## &#xA;## Residuals:&#xA;##      Min       1Q   Median       3Q      Max &#xA;## -2.00733 -0.21715  0.01177  0.23456  1.27305 &#xA;## &#xA;## Coefficients:&#xA;##               Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)  5.6482483  0.5462963  10.339  &amp;lt; 2e-16 ***&#xA;## educ         0.0184559  0.0410608   0.449 0.653192    &#xA;## exper        0.0139072  0.0031768   4.378 1.34e-05 ***&#xA;## tenure       0.0113929  0.0024397   4.670 3.46e-06 ***&#xA;## married      0.2008658  0.0388267   5.173 2.82e-07 ***&#xA;## south       -0.0802354  0.0262560  -3.056 0.002308 ** &#xA;## urban        0.1835758  0.0268586   6.835 1.49e-11 ***&#xA;## black       -0.1466989  0.0397013  -3.695 0.000233 ***&#xA;## IQ          -0.0009418  0.0051625  -0.182 0.855289    &#xA;## educ:IQ      0.0003399  0.0003826   0.888 0.374564    &#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 0.3632 on 925 degrees of freedom&#xA;## Multiple R-squared:  0.2634, Adjusted R-squared:  0.2563 &#xA;## F-statistic: 36.76 on 9 and 925 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div id=&#34;example-9.4&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Example 9.4&lt;/h3&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;crime2&amp;quot;)&#xA;&#xA;lm.9.4.1 &amp;lt;- lm(lcrmrte ~ unem + llawexpc, data = crime2, subset = (d87==1))&#xA;summary(lm.9.4.1)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = lcrmrte ~ unem + llawexpc, data = crime2, subset = (d87 == &#xA;##     1))&#xA;## &#xA;## Residuals:&#xA;##      Min       1Q   Median       3Q      Max &#xA;## -0.64786 -0.22955 -0.06368  0.22183  0.71164 &#xA;## &#xA;## Coefficients:&#xA;##             Estimate Std. Error t value Pr(&amp;gt;|t|)  &#xA;## (Intercept)  3.34290    1.25053   2.673   0.0106 *&#xA;## unem        -0.02900    0.03234  -0.897   0.3748  &#xA;## llawexpc     0.20337    0.17265   1.178   0.2453  &#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 0.3231 on 43 degrees of freedom&#xA;## Multiple R-squared:  0.05712,    Adjusted R-squared:  0.01326 &#xA;## F-statistic: 1.302 on 2 and 43 DF,  p-value: 0.2824&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm.9.4.2 &amp;lt;- lm(lcrmrte ~ unem + llawexpc + lcrmrt_1, data = crime2, subset = (d87==1))&#xA;summary(lm.9.4.2)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = lcrmrte ~ unem + llawexpc + lcrmrt_1, data = crime2, &#xA;##     subset = (d87 == 1))&#xA;## &#xA;## Residuals:&#xA;##      Min       1Q   Median       3Q      Max &#xA;## -0.48081 -0.12202  0.00659  0.14658  0.34428 &#xA;## &#xA;## Coefficients:&#xA;##              Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept)  0.076451   0.821143   0.093    0.926    &#xA;## unem         0.008621   0.019517   0.442    0.661    &#xA;## llawexpc    -0.139576   0.108641  -1.285    0.206    &#xA;## lcrmrt_1     1.193923   0.132099   9.038  2.1e-11 ***&#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 0.1905 on 42 degrees of freedom&#xA;## Multiple R-squared:  0.6798, Adjusted R-squared:  0.657 &#xA;## F-statistic: 29.73 on 3 and 42 DF,  p-value: 1.799e-10&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div id=&#34;example-9.8&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Example 9.8&lt;/h3&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;rdchem&amp;quot;)&#xA;&#xA;lm.9.8.1 &amp;lt;- lm(rdintens ~ sales + profmarg, data = rdchem)&#xA;summary(lm.9.8.1)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = rdintens ~ sales + profmarg, data = rdchem)&#xA;## &#xA;## Residuals:&#xA;##     Min      1Q  Median      3Q     Max &#xA;## -2.2221 -1.1414 -0.6068  0.5008  6.3702 &#xA;## &#xA;## Coefficients:&#xA;##              Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept) 2.625e+00  5.855e-01   4.484 0.000106 ***&#xA;## sales       5.338e-05  4.407e-05   1.211 0.235638    &#xA;## profmarg    4.462e-02  4.618e-02   0.966 0.341966    &#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 1.862 on 29 degrees of freedom&#xA;## Multiple R-squared:  0.07612,    Adjusted R-squared:  0.0124 &#xA;## F-statistic: 1.195 on 2 and 29 DF,  p-value: 0.3173&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# See the outliers&#xA;with(rdchem, plot(sales, rdintens, pch = 16))&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://www.r-econometrics.com/reproduction/wooldridge/wooldridge09_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;480&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data Visualisation in R Using ggplot2</title>
      <link>https://www.r-econometrics.com/rbasics/ggplotintro/</link>
      <pubDate>Sun, 04 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/rbasics/ggplotintro/</guid>
      <description>&lt;p&gt;A major challenge in data analysis is to summarise and present data with informative graphs. The &lt;code&gt;ggplot2&lt;/code&gt; package was specifically designed to help with this task. Since it is a very powerful and well documented package&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;, this introduction will only focus on its basic syntax, so that the user gets a better understanding of how to read the supporting material on the internet.&lt;/p&gt;&#xA;&lt;p&gt;ggplot graphs are built with some kind of blocks, which usually start with the function &lt;code&gt;ggplot&lt;/code&gt;. Its first argument contains the data object and the second argument is a further function called &lt;code&gt;aes&lt;/code&gt;.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; It controls, which columns of the data frame are used for the axes, colours, shapes of the data points and further features of the graph. The remaining blocks are separated by plus &lt;code&gt;+&lt;/code&gt; signs and – if not specified otherwise – take the information from the first block and add a certain aspect to the graph, for example additional lines or data points. To understand what this all means, let us look at some basic examples.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Installing R and RStudio</title>
      <link>https://www.r-econometrics.com/rbasics/installation/</link>
      <pubDate>Sun, 04 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/rbasics/installation/</guid>
      <description>&lt;p&gt;For this introduction I recommend to install two software packages on your system:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;em&gt;R&lt;/em&gt;: The software, which does all the calculations.&lt;/li&gt;&#xA;&lt;li&gt;&lt;em&gt;RStudio&lt;/em&gt;: The working environment, where all the code will be developed.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;em&gt;Note that the instructions of this section were written for a standard installation on a private computer. If you work on a corporate machine, the installation could be different due to different IT requirements of your company.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;div id=&#34;installing-r&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Installing R&lt;/h2&gt;&#xA;&lt;p&gt;A proper installation of R is the prerequisite of everything that will follow. Fortunately, installing R is easy and can be done quickly by following these steps:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Statistical Inference</title>
      <link>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge04/</link>
      <pubDate>Sun, 04 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/wooldridge/wooldridge04/</guid>
      <description>&lt;p&gt;Before we start, let’s clear our memory, set the working directory and load the &lt;code&gt;wooldridge&lt;/code&gt; data package.&lt;/p&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(list = ls())&#xA;&#xA;setwd(&amp;quot;C:/path/to/the/working/directory&amp;quot;)&#xA;&#xA;library(wooldridge)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(wage1)&#xA;&#xA;lm.1 &amp;lt;- lm(lwage ~ educ + exper + tenure, data = wage1)&#xA;s.1 &amp;lt;- summary(lm.1)&#xA;s.1&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;## &#xA;## Call:&#xA;## lm(formula = lwage ~ educ + exper + tenure, data = wage1)&#xA;## &#xA;## Residuals:&#xA;##      Min       1Q   Median       3Q      Max &#xA;## -2.05802 -0.29645 -0.03265  0.28788  1.42809 &#xA;## &#xA;## Coefficients:&#xA;##             Estimate Std. Error t value Pr(&amp;gt;|t|)    &#xA;## (Intercept) 0.284360   0.104190   2.729  0.00656 ** &#xA;## educ        0.092029   0.007330  12.555  &amp;lt; 2e-16 ***&#xA;## exper       0.004121   0.001723   2.391  0.01714 *  &#xA;## tenure      0.022067   0.003094   7.133 3.29e-12 ***&#xA;## ---&#xA;## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&#xA;## &#xA;## Residual standard error: 0.4409 on 522 degrees of freedom&#xA;## Multiple R-squared:  0.316,  Adjusted R-squared:  0.3121 &#xA;## F-statistic: 80.39 on 3 and 522 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;In order to be able to use the values of the coefficients for further calculations, you can use copy and paste with the numbers provided in the summary &lt;code&gt;s.1&lt;/code&gt;. Alternatively, and for the sake of more precision, you can access the coefficients directly. If you use the &lt;code&gt;names&lt;/code&gt; function and run &lt;code&gt;names(s.1)&lt;/code&gt;, you will notice a subdirectory called &lt;em&gt;coefficients&lt;/em&gt;, which contains the coefficients, standard errors, t-statistics and p-values of the regression. Entering &lt;code&gt;s.1$coefficients&lt;/code&gt; or &lt;code&gt;coefficients(s.1)&lt;/code&gt; gives those values for all coefficients, but you can also extract them separately using the &lt;code&gt;[row, column]&lt;/code&gt; signs, where the first value defines the row index and the second the column index. If no value is specified for a row or column, R will use all available values. This happens in the third line of the following code, where the t-values are calculated from the betas and their respective standard errors. The forth line of the code specifies a certain row which means that the t-value is calculated only for the parameter listed third in the coefficient list.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Reproduction: Sheperd, B. (2016). The gravity model of international trade: A user guide.</title>
      <link>https://www.r-econometrics.com/reproduction/2016_sheperd_gravity/</link>
      <pubDate>Tue, 30 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/2016_sheperd_gravity/</guid>
      <description>&lt;p&gt;The updated paper and dataset can be downloaded from &lt;a href=&#34;http://www.unescap.org/resources/gravity-model-international-trade-user-guide-updated-version&#34; target=&#34;_blank&#34;&gt;UNESCAP&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;div id=&#34;load-libraries-and-read-data&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Load libraries and read data&lt;/h2&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(AER)&#xA;library(dplyr)&#xA;library(foreign)&#xA;library(ggplot2)&#xA;library(lmtest)&#xA;library(multiwayvcov)&#xA;library(sampleSelection)&#xA;&#xA;data &amp;lt;- read.dta(&amp;quot;servicesdataset_2016.dta&amp;quot;)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div id=&#34;correlations&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Correlations&lt;/h2&gt;&#xA;&lt;p&gt;Table 1&lt;/p&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- data %&amp;gt;% &#xA;  mutate(ln_trade = log(trade),&#xA;         ln_distance = log(dist),&#xA;         ln_gdp_exp = log(gdp_exp),&#xA;         ln_gdp_imp = log(gdp_imp))&#xA;&#xA;cor.data &amp;lt;- data %&amp;gt;% &#xA;  filter(sector == &amp;quot;SER&amp;quot;) %&amp;gt;% &#xA;  select(ln_trade, ln_gdp_exp, ln_gdp_imp, ln_distance) %&amp;gt;%&#xA;  na.omit %&amp;gt;% &#xA;  filter(ln_trade &amp;gt; -Inf)&#xA;&#xA;round(cor(cor.data), 4)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;##             ln_trade ln_gdp_exp ln_gdp_imp ln_distance&#xA;## ln_trade      1.0000     0.3643     0.3731     -0.2648&#xA;## ln_gdp_exp    0.3643     1.0000    -0.3103      0.0518&#xA;## ln_gdp_imp    0.3731    -0.3103     1.0000      0.0431&#xA;## ln_distance  -0.2648     0.0518     0.0431      1.0000&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div id=&#34;graphics&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Graphics&lt;/h2&gt;&#xA;&lt;p&gt;Prepare data&lt;/p&gt;</description>
    </item>
    <item>
      <title>About and Disclaimer</title>
      <link>https://www.r-econometrics.com/about/</link>
      <pubDate>Mon, 15 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/about/</guid>
      <description>&lt;p&gt;My name is Franz Mohr and I am an Austrian graduate from &lt;a href=&#34;http://www.jku.at/&#34; target=&#34;_blank&#34;&gt;Johannes Kepler University Linz&lt;/a&gt;, where I also worked as a TA at the &lt;a href=&#34;http://www.econ.jku.at/&#34; target=&#34;_blank&#34;&gt;department of economics&lt;/a&gt; (public finance and macro-related fields). After working for &lt;a href=&#34;https://www.oenb.at/en/&#34; target=&#34;_blank&#34;&gt;the Oesterreichische Nationalbank (OeNB)&lt;/a&gt; - the Austrian central bank - I am currently employed at the &lt;a href=&#34;https://www.fma.gv.at/en/&#34; target=&#34;_blank&#34;&gt;Austrian Financial Market Authority (FMA)&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Disclaimer&lt;/strong&gt;: The opinions expressed on this website are those of the author and do not necessarily reflect the official viewpoint of the Austrian Financial Market Authority.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
