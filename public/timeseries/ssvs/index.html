 
<!DOCTYPE html>
<html xmlns="//www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
    <head>
        

        
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-115075361-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-115075361-1');
</script>
        
        <meta http-equiv="content-type" content="text/html; charset=utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1" />

        <title>Stochastic Search Variable Selection &middot; r-econometrics</title>
        <link rel='stylesheet' href='//fonts.googleapis.com/css?family=Open+Sans:400,300,600' type='text/css'>
        <link rel="stylesheet" href="https://www.r-econometrics.com//libraries/normalize.3.0.1.css" />
        <link rel="stylesheet" href="https://www.r-econometrics.com//css/liquorice.css" />
        <link rel="shortcut icon" href="/favicon.ico" />
        <link rel="apple-touch-icon-precomposed" href="/apple-touch-icon-144-precomposed.png" sizes="144x144" />
        </head>
    <body class="li-body">

<header class="li-page-header">
    <div class="container">
        <div class="row">
            <div class="sixteen columns">
                <div class="li-brand li-left">
                <a href="https://www.r-econometrics.com/">r-econometrics</a></div>
                <div class="li-menu li-right">
                    <span class="li-menu-icon" onclick="javascript:toggle('menu');">&#9776;</span>
                    <ul id="menu2" class="li-menu-items">
                        
                            <li><a href="/rbasicsintro"> R(eal) Basics </a></li>
                        
                            <li><a href="/methodsintro"> Econometric Methods </a></li>
                        
                            <li><a href="/timeseriesintro"> Time Series Topics </a></li>
                        
                            <li><a href="/networksintro"> Network Analysis </a></li>
                        
                            <li><a href="/links"> Links </a></li>
                        
                            <li><a href="/post"> Blog </a></li>
                        
                            <li><a href="/reproductionintro"> Reproduction Projects </a></li>
                        
                            <li><a href="/about"> About and Disclaimer </a></li>
                        
                    </ul>
                </div>
            </div>
        </div>
        <div class="row">
            <div class="sixteen columns">
                <ul id="menu" class="li-menu-items li-menu-mobile">
                    
                        <li><a href="/rbasicsintro"> R(eal) Basics </a></li>
                    
                        <li><a href="/methodsintro"> Econometric Methods </a></li>
                    
                        <li><a href="/timeseriesintro"> Time Series Topics </a></li>
                    
                        <li><a href="/networksintro"> Network Analysis </a></li>
                    
                        <li><a href="/links"> Links </a></li>
                    
                        <li><a href="/post"> Blog </a></li>
                    
                        <li><a href="/reproductionintro"> Reproduction Projects </a></li>
                    
                        <li><a href="/about"> About and Disclaimer </a></li>
                    
                </ul>
            </div>
        </div>
    </div>
</header>






  <meta
     name="description"
     content=""
   />

    <div class="container">
        <div class="row">
            <div class="sixteen columns">
                <article class="li-article">
                    <header class="li-article-header">
                        <h1 class="li-article-title">Stochastic Search Variable Selection</h1>
                        <span class="li-article-taxonomies">
                            

                            
                                with tags
                                
                                    <a href="https://www.r-econometrics.com//tags/r">r</a>
                                
                                    <a href="https://www.r-econometrics.com//tags/bvar">bvar</a>
                                
                                    <a href="https://www.r-econometrics.com//tags/var">var</a>
                                
                                    <a href="https://www.r-econometrics.com//tags/ssvs">ssvs</a>
                                
                                    <a href="https://www.r-econometrics.com//tags/bvartools">bvartools</a>
                                
                            
                        </span>
                         - 
                        <time class="li-article-date">
                          Franz X. Mohr, Created: June 11, 2019, Last update: June 11, 2019
                         
                        </time>
                    </header>
                    <section>
                        


<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>A general drawback of vector autoregressive (VAR) models is that the number of estimated coefficients increases disproportionately with the number of lags. Therefore, fewer information per parameter is available for the estimation as the number of lags increases. In the Bayesian VAR literature one approach to mitigate this so-called <em>curse of dimensionality</em> is <em>stochastic search variable selection</em> (SSVS) as proposed by George et al. (2008). The basic idea of SSVS is to assign commonly used prior variances to parameters, which should be included in a model, and prior variances close to zero to irrelevant parameters. By that, relevant parameters are estimated in the usual way and posterior draws of irrelevant variables are close to zero so that they have no significant effect on forecasts and impulse responses. This is achieved by adding a hierarchial prior to the model, where the relevance of a variable is assessed in each step of the sampling algorithm.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
<p>This post presents code for the estimation of a Bayesian vector autoregressive (BVAR) model with SSVS. It uses <a href="http://www.jmulti.de/download/datasets/e1.dat">dataset E1</a> from Lütkepohl (2007), which contains data on West German fixed investment, disposable income and consumption expenditures in billions of DM from 1960Q1 to 1982Q4. Following a related example in Lütkepohl (2007, Section 5.2.10) only the first 71 observations of a VAR(4) model are used. The <code>bvartools</code> package can be used to load the data and generate the data matrices:</p>
<pre class="r"><code>library(bvartools) # install.packages(&quot;bvartools&quot;)

# Load and transform data
data(&quot;e1&quot;)
e1 &lt;- diff(log(e1))

# Generate VAR
data &lt;- gen_var(e1, p = 4, deterministic = &quot;const&quot;)

# Get data matrices
y &lt;- data$Y[, 1:71]
x &lt;- data$Z[, 1:71]</code></pre>
</div>
<div id="estimation" class="section level2">
<h2>Estimation</h2>
<p>The prior variances of the parameters are set in accordance with the semiautomatic approach described in George et al. (2008). Hence, the prior variance of the <span class="math inline">\(i\)</span>th parameter is set to <span class="math inline">\(\tau_{1,i}^2 = (10 \hat{\sigma}_i)^2\)</span> if this parameter should be included in the model and to <span class="math inline">\(\tau_{0,i}^2 = (0.1 \hat{\sigma}_i)^2\)</span> if it should be excluded. <span class="math inline">\(\hat{\sigma}_i\)</span> is the standard error associated with the unconstrained least squares estimate of parameter <span class="math inline">\(i\)</span>. For all variables the prior inclusion probabilities are set to 0.5. The prior of the error variance-covariance matrix is uninformative.</p>
<pre class="r"><code># Reset random number generator for reproducibility
set.seed(1234567)

t &lt;- ncol(y) # Number of observations
k &lt;- nrow(y) # Number of endogenous variables
m &lt;- k * nrow(x) # Number of estimated coefficients

# Coefficient priors
a_mu_prior &lt;- matrix(0, m) # Vector of prior means

# SSVS priors (semiautomatic approach)
ols &lt;- tcrossprod(y, x) %*% solve(tcrossprod(x)) # OLS estimates
sigma_ols &lt;- tcrossprod(y - ols %*% x) / (t - nrow(x)) # OLS error covariance matrix
cov_ols &lt;- kronecker(solve(tcrossprod(x)), sigma_ols)
se_ols &lt;- matrix(sqrt(diag(cov_ols))) # OLS standard errors

tau0 &lt;- se_ols * 0.1 # Prior if excluded
tau1 &lt;- se_ols * 10 # Prior if included

# Prior for inclusion parameter
prob_prior &lt;- matrix(0.5, m)

# Prior for variance-covariance matrix
u_sigma_df_prior &lt;- 0 # Prior degrees of freedom
u_sigma_scale_prior &lt;- diag(0, k) # Prior covariance matrix
u_sigma_df_post &lt;- t + u_sigma_df_prior # Posterior degrees of freedom</code></pre>
<p>The initial parameter values are set to zero and their corresponding prior variances are set to <span class="math inline">\(\tau_1^2\)</span>, which implies that all parameters should be estimated relatively freely in the first step of the Gibbs sampler.</p>
<pre class="r"><code># Initial values
a &lt;- matrix(0, m)
a_v_i_prior &lt;- diag(1 / c(tau1)^2, m) # Inverse of the prior covariance matrix

# Data containers for posterior draws
iter &lt;- 15000 # Number of total Gibs sampler draws
burnin &lt;- 5000 # Number of burn-in draws

store &lt;- iter - burnin
draws_a &lt;- matrix(NA, m, store)
draws_lambda &lt;- matrix(NA, m, store)
draws_sigma &lt;- matrix(NA, k^2, store)</code></pre>
<p>SSVS can be added to a standard Gibbs sampler algorithm for VAR models in a straightforward manner. The <code>ssvs</code> function can be used to obtain a draw of inclusion parameters and its corresponding inverted prior variance matrix. It requires the current draw of parameters, standard errors <span class="math inline">\(\tau_0\)</span> and <span class="math inline">\(\tau_1\)</span>, and prior inclusion probabilities as arguments. In this example constant terms are excluded from SSVS, which is achieved by specifying <code>include = 1:36</code>. Hence, only parameters 1 to 36 are considered by the function and the remaining three parameters have prior variances that correspond to their values in <span class="math inline">\(\tau_1^2\)</span>.</p>
<pre class="r"><code># Reset random number generator for reproducibility
set.seed(1234567)

# Start Gibbs sampler
for (draw in 1:iter) {
  # Draw variance-covariance matrix
  u &lt;- y - matrix(a, k) %*% x # Obtain residuals
  # Scale posterior
  u_sigma_scale_post &lt;- solve(u_sigma_scale_prior + tcrossprod(u))
  # Draw posterior of inverse sigma
  u_sigma_i &lt;- matrix(rWishart(1, u_sigma_df_post, u_sigma_scale_post)[,, 1], k)
  # Obtain sigma
  u_sigma &lt;- solve(u_sigma_i)
  
  # Draw conditional mean parameters
  a &lt;- post_normal(y, x, u_sigma_i, a_mu_prior, a_v_i_prior)
  
  # Draw inclusion parameters and update priors
  temp &lt;- ssvs(a, tau0, tau1, prob_prior, include = 1:36)
  a_v_i_prior &lt;- temp$V_i # Update prior
  
  # Store draws
  if (draw &gt; burnin) {
    draws_a[, draw - burnin] &lt;- a
    draws_lambda[, draw - burnin] &lt;- temp$lambda
    draws_sigma[, draw - burnin] &lt;- u_sigma
  }
}</code></pre>
<p>The output of a Gibbs sampler with SSVS can be further analysed in the usual way. Therefore, point estimates can be obtained by calculating the means of the parameters’ posterior draws:</p>
<pre class="r"><code>A &lt;- rowMeans(draws_a) # Obtain means for every parameter
A &lt;- matrix(A, k) # Transform mean vector into matrix
A &lt;- round(A, 3) # Round values
dimnames(A) &lt;- list(dimnames(y)[[1]], dimnames(x)[[1]]) # Rename matrix dimensions

t(A) # Print</code></pre>
<pre><code>##          invest income   cons
## invest.1 -0.102  0.011 -0.002
## income.1  0.044 -0.031  0.168
## cons.1    0.074  0.140 -0.287
## invest.2 -0.013  0.002  0.004
## income.2  0.015  0.004  0.315
## cons.2    0.027 -0.001  0.006
## invest.3  0.033  0.000  0.000
## income.3 -0.008  0.021  0.013
## cons.3   -0.043  0.007  0.019
## invest.4  0.250  0.001 -0.005
## income.4 -0.064 -0.010  0.025
## cons.4   -0.023  0.001  0.000
## const     0.014  0.017  0.014</code></pre>
<p>It is also possible to obtain the posterior inclusion probabilites of each variable by calculating the means of their posterior draws. As can be seen in the output below, only few variables appear to be relevant in the VAR(4) model, because most inclusion probabilities are relatively low. The inclusion probabilities of the constant terms are 100 percent, because they were excluded from SSVS.</p>
<pre class="r"><code>lambda &lt;- rowMeans(draws_lambda) # Obtain means for every row
lambda &lt;- matrix(lambda, k) # Transform mean vector into a matrix
lambda &lt;- round(lambda, 2) # Round values
dimnames(lambda) &lt;- list(dimnames(y)[[1]], dimnames(x)[[1]]) # Rename matrix dimensions

t(lambda) # Print</code></pre>
<pre><code>##          invest income cons
## invest.1   0.43   0.23 0.10
## income.1   0.10   0.18 0.67
## cons.1     0.11   0.40 0.77
## invest.2   0.11   0.09 0.14
## income.2   0.08   0.07 0.98
## cons.2     0.07   0.06 0.08
## invest.3   0.19   0.07 0.06
## income.3   0.06   0.13 0.10
## cons.3     0.09   0.07 0.12
## invest.4   0.78   0.09 0.16
## income.4   0.13   0.09 0.18
## cons.4     0.09   0.07 0.06
## const      1.00   1.00 1.00</code></pre>
<p>Given these values, the researcher could proceed in the usual way and obtain forecasts and impulse responses based on the output of the Gibbs sampler. The advantage of this approach is that it does not only take into account parameter uncertainty, but also model uncertainty. This can be illustrated by the histogram of the posterior draws of the 6th coefficient, which describes the relationship between the first lag of income and the current value of consumption.</p>
<pre class="r"><code>hist(draws_a[6,], main = &quot;Consumption ~ First lag of income&quot;, xlab = &quot;Value of posterior draw&quot;)</code></pre>
<p><img src="/timeseries/ssvs_files/figure-html/unnamed-chunk-6-1.png" width="432" /></p>
<p>A non-negligible mass of some 23 percent, i.e. 1 - 0.67, of the parameter draws is concentrated around zero. This is the result of SSVS, where posterior draws are close to zero if a constant is assessed to be irrelevant during an iteration of the Gibbs sampler and, therefore, <span class="math inline">\(\tau_{0,6}^2\)</span> is used as its prior variance. On the other hand, about 67 percent of the draws are dispersed around a positive value, where SSVS suggests to include the variable in the model and the larger value <span class="math inline">\(\tau_{1,6}^2\)</span> is used as prior variance. Model uncertainty is then described by the two peaks and parameter uncertainty by the dispersion of the posterior draws around them.</p>
<p>However, if the researcher prefers not want to work with a model, where the relevance of a variable can change from one step of the sampling algorithm to another, a different approach would be to work only with a highly probable model. This can be done with a further simulation, where very tight priors are used for irrelevant variables and relatively uninformative priors for relevant parameters. In this example, coefficients with a posterior inclusion probability of above 40 percent are considered to be relevant.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> The prior variance is set to 0.00001 for irrelevant and to 9 for relevant variables. No additional SSVS step is required. Everything else remains unchanged.</p>
<pre class="r"><code># Select variables that should be included
include_var &lt;- c(lambda &gt;= .4)

# Update prior variances
diag(a_v_i_prior)[!include_var] &lt;- 100000 # Very tight prior close to zero
diag(a_v_i_prior)[include_var] &lt;- 1 / 9 # Relatively uninformative prior

# Data containers for posterior draws
draws_a &lt;- matrix(NA, m, store)
draws_sigma &lt;- matrix(NA, k^2, store)

# Start Gibbs sampler
for (draw in 1:iter) {
  # Draw conditional mean parameters
  a &lt;- post_normal(y, x, u_sigma_i, a_mu_prior, a_v_i_prior)
  
  # Draw variance-covariance matrix
  u &lt;- y - matrix(a, k) %*% x # Obtain residuals
  u_sigma_scale_post &lt;- solve(u_sigma_scale_prior + tcrossprod(u))
  u_sigma_i &lt;- matrix(rWishart(1, u_sigma_df_post, u_sigma_scale_post)[,, 1], k)
  u_sigma &lt;- solve(u_sigma_i) # Invert Sigma_i to obtain Sigma
  
  # Store draws
  if (draw &gt; burnin) {
    draws_a[, draw - burnin] &lt;- a
    draws_sigma[, draw - burnin] &lt;- u_sigma
  }
}</code></pre>
<p>The means of the posterior draws are similar to the OLS estimates in Lütkepohl (2007, Section 5.2.10):</p>
<pre class="r"><code>A &lt;- rowMeans(draws_a) # Obtain means for every row
A &lt;- matrix(A, k) # Transform mean vector into a matrix
A &lt;- round(A, 3) # Round values
dimnames(A) &lt;- list(dimnames(y)[[1]], dimnames(x)[[1]]) # Rename matrix dimensions

t(A) # Print</code></pre>
<pre><code>##          invest income   cons
## invest.1 -0.219  0.001 -0.001
## income.1  0.000  0.000  0.262
## cons.1    0.000  0.238 -0.334
## invest.2  0.000  0.000  0.001
## income.2  0.000  0.000  0.329
## cons.2    0.000  0.000  0.000
## invest.3  0.000  0.000  0.000
## income.3  0.000  0.000  0.000
## cons.3    0.000  0.000  0.000
## invest.4  0.328  0.000 -0.001
## income.4  0.000  0.000  0.000
## cons.4    0.000  0.000  0.000
## const     0.015  0.015  0.014</code></pre>
</div>
<div id="evaluation" class="section level2">
<h2>Evaluation</h2>
<p>The <code>bvar</code> function can be used to collect relevant output of the Gibbs sampler into a standardised object, which can be used by further functions such as <code>predict</code> to obtain forecasts or <code>irf</code> for impulse respons analysis.</p>
<pre class="r"><code>bvar_est &lt;- bvar(y = y, x = x, A = draws_a[1:36,],
                 C = draws_a[37:39, ], Sigma = draws_sigma)</code></pre>
<p>Posterior draws can be thinned with function <code>thin</code>:</p>
<pre class="r"><code>bvar_est &lt;- thin(bvar_est, thin = 5)</code></pre>
<div id="forecasts" class="section level3">
<h3>Forecasts</h3>
<p>Forecasts with credible bands can be obtained with the function <code>predict</code>. If the model contains deterministic terms, new values can be provided in the argument <code>new_D</code>. If no values are provided, the function sets them to zero. The number of rows of <code>new_D</code> must be the same as the argument <code>n.ahead</code>.</p>
<pre class="r"><code>bvar_pred &lt;- predict(bvar_est, n.ahead = 10, new_D = rep(1, 10))

plot(bvar_pred)</code></pre>
<p><img src="/timeseries/ssvs_files/figure-html/forecasts-1.png" width="528" /></p>
</div>
<div id="impulse-response-analysis" class="section level3">
<h3>Impulse response analysis</h3>
<pre class="r"><code>OIR &lt;- irf(bvar_est, impulse = &quot;income&quot;, response = &quot;cons&quot;, n.ahead = 8, type = &quot;oir&quot;)

plot(OIR, main = &quot;Orthogonalised Impulse Response&quot;, xlab = &quot;Period&quot;, ylab = &quot;Response&quot;)</code></pre>
<p><img src="/timeseries/ssvs_files/figure-html/oir-1.png" width="528" /></p>
</div>
</div>
<div id="references" class="section level2">
<h2>References</h2>
<p>George, E. I., Sun, D., &amp; Ni, S. (2008). Bayesian stochastic search for VAR model restrictions. <em>Journal of Econometrics, 142</em>(1), 553-580. <a href="https://doi.org/10.1016/j.jeconom.2007.08.017" class="uri">https://doi.org/10.1016/j.jeconom.2007.08.017</a></p>
<p>Koop, G., &amp; Korobilis, D. (2010). Bayesian multivariate time series methods for empirical macroeconomics. <em>Foundations and trends in econometrics, 3</em>(4), 267-358. <a href="https://dx.doi.org/10.1561/0800000013" class="uri">https://dx.doi.org/10.1561/0800000013</a></p>
<p>Lütkepohl, H. (2007). <em>New introduction to multiple time series analysis</em> (2nd ed.). Berlin: Springer.</p>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>See Koop and Korobilis (2010) for an introduction to Bayesian VAR modelling and SSVS.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>This threshold value is usually set to 50 percent. 40 percent is chosen, because it yields similar results as the restricted model in Lütkepohl (2007, Section 5.2.10).<a href="#fnref2">↩</a></p></li>
</ol>
</div>

                    </section>
                </article>
                <div class="container">
  <div class="row">
    <div class="sixteen columns center">
      
      <div class="addthis_inline_share_toolbox"></div>
    </div>
  </div>
</div>

                
<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5a9c6c9b8a39890d"></script>
                
                <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<footer class="li-page-footer">
    <div class="container">
        <div class="row">
            <div class="sixteen columns center">
              <div id="disqus_thread"></div>
                <script type="text/javascript">
                  (function() { 
                  if (window.location.hostname == "localhost") return;
                  var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                  var disqus_shortname = 'r-econometrics';
                  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                  })();
                  </script>
                  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
                  <a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
            </div>
        </div>
    </div>
</footer>
            </div>
        </div>
        
    </div>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<footer class="li-page-footer">
    <div class="container">
        <div class="row">
            <div class="sixteen columns center">
              <div class="li-page-footer-legal">
                &copy; Franz X. Mohr. Powered by <a href="https://github.com/rstudio/blogdown" target="_blank" >Blogdown</a> and hosted by <a href="https://www.netlify.com/" target="_blank" >Netlify</a>. Source available on <a href="https://github.com/franzmohr/r-econometrics" target="_blank" >Github</a>.
              </div>
              <div class="li-page-footer-theme">
                <span class=""><a href="https://github.com/eliasson/liquorice/">liquorice</a> is a theme for <a href="https://gohugo.io/">hugo</a>
                </span>
              </div>
            </div>
        </div>
    </div>
</footer>

    <script src="//yihui.name/js/math-code.js"></script>
    <script async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>

    <script type="text/javascript">
    
    function toggle(id) {
        var e = document.getElementById(id);
        e.style.display == 'block' ? e.style.display = 'none' : e.style.display = 'block';
    }

    </script>
    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-115075361-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
    </body>
</html>

