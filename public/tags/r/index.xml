<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on r-econometrics</title>
    <link>https://www.r-econometrics.com/tags/r/</link>
    <description>Recent content in R on r-econometrics</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 11 Sep 2023 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://www.r-econometrics.com/tags/r/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Bayesian Inference of Structural Vector Autoregressions (SVAR) with the `bvartools` package</title>
      <link>https://www.r-econometrics.com/timeseries/bayes-svar-intro/</link>
      <pubDate>Mon, 11 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/timeseries/bayes-svar-intro/</guid>
      <description>&lt;p&gt;The &lt;a href=&#34;https://cran.r-project.org/package=bvartools&#34; target=&#34;_blank&#34;&gt;bvartools&lt;/a&gt; allows to perform Bayesian inference of &lt;a href=&#34;https://www.r-econometrics.com/timeseries/varintro&#34; target=&#34;_blank&#34;&gt;Vector autoregressive (VAR) models&lt;/a&gt;, including &lt;a href=&#34;https://www.r-econometrics.com/timeseries/svarintro&#34; target=&#34;_blank&#34;&gt;structural VARs&lt;/a&gt;. This post guides through the Bayesian inference of SVAR models in R using the &lt;code&gt;bvartools&lt;/code&gt; package.&lt;/p&gt;&#xA;&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Data&lt;/h2&gt;&#xA;&lt;p&gt;For this illustration we generate an artificial data set with three endogenous variables, which follows the data generating process&lt;/p&gt;&#xA;&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_t = A_1 y_{t - 1} + B \epsilon_t,\]&lt;/span&gt;&lt;/p&gt;&#xA;&lt;p&gt;where&lt;/p&gt;&#xA;&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[&#xA;A_1 = \begin{bmatrix} 0.3 &amp;amp; 0.12 &amp;amp; 0.69 \\ 0 &amp;amp; 0.3 &amp;amp; 0.48 \\ 0.24 &amp;amp; 0.24 &amp;amp; 0.3 \end{bmatrix} \text{, }&#xA;B = \begin{bmatrix} 1 &amp;amp; 0 &amp;amp; 0 \\ -0.14 &amp;amp; 1 &amp;amp; 0 \\ -0.06 &amp;amp; 0.39 &amp;amp; 1 \end{bmatrix} \text{ and } \epsilon_t \sim N(0, I_3).&#xA;\]&lt;/span&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Introduction to Dynamic Factor Models</title>
      <link>https://www.r-econometrics.com/timeseries/dynamicfactorintro/</link>
      <pubDate>Sun, 25 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/timeseries/dynamicfactorintro/</guid>
      <description>&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;For some macroeconomic applications it might be interesting to see whether a set of obserable variables depends on common drivers. The estimation of such common factors can be done using so-called &lt;em&gt;factor analytical models&lt;/em&gt;, which have the form&lt;/p&gt;&#xA;&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[x_t = \lambda f_t + u_t,\]&lt;/span&gt;&lt;/p&gt;&#xA;&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(x_t\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;-dimensional vector of observable variables, &lt;span class=&#34;math inline&#34;&gt;\(f_t\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(N \times 1\)&lt;/span&gt; vector of unobserved factors, &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; is an &lt;span class=&#34;math inline&#34;&gt;\(M \times N\)&lt;/span&gt; matrix of factor loadings and &lt;span class=&#34;math inline&#34;&gt;\(u_t\)&lt;/span&gt; is an error term.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Short Notes on Bayesian Inference of Vector Autoregressive Models</title>
      <link>https://www.r-econometrics.com/timeseries/bayesnotes/</link>
      <pubDate>Sun, 16 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/timeseries/bayesnotes/</guid>
      <description>&lt;p&gt;During the past years I realised that econometric analyis can be understood as a craft. You learn your basics at school from more or less motivated/talented professors and then you are sent out into wild, where you are confronted with real life challenges that differ from the stylised exmples you have become used to during your studies. This comes with a bunch new insights that I want to document on this page. It should become a collection of notes on Bayesian VAR modelling that have become imporant to me over the last years.&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Introduction to Structural Vector Autoregression (SVAR)</title>
      <link>https://www.r-econometrics.com/timeseries/svarintro/</link>
      <pubDate>Thu, 13 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/timeseries/svarintro/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.r-econometrics.com/timeseries/varintro&#34; target=&#34;_blank&#34;&gt;Vector autoregressive (VAR) models&lt;/a&gt; constitute a rather general approach to modelling multivariate time series. A critical drawback of those models in their standard form is their missing ability to describe contemporaneous relationships between the analysed variables. This becomes a central issue in the &lt;a href=&#34;https://www.r-econometrics.com/timeseries/irf&#34; target=&#34;_blank&#34;&gt;impulse response analysis&lt;/a&gt; for such models, where it is important to know the contemporaneous effects of a shock to the economy. Usually, researchers address this by using orthogonal impulse responses, where the correlation between the errors is obtained from the (lower) Cholesky decomposition of the error covariance matrix. This requires them to arrange the variables of the model in a suitable order. An alternative to this approach is to use so-called &lt;em&gt;structural vector autoregressive (SVAR)&lt;/em&gt; models, where the relationship between contemporaneous variables is modelled more directly. This post provides an introduction to the concept of SVAR models and how they can be estimated in R.&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Introduction to Stationarity and Unit Roots in Time Series Analysis</title>
      <link>https://www.r-econometrics.com/timeseries/stationarity/</link>
      <pubDate>Sun, 09 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/timeseries/stationarity/</guid>
      <description>&lt;div id=&#34;concepts&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Concepts&lt;/h2&gt;&#xA;&lt;p&gt;Basically &lt;strong&gt;stationarity&lt;/strong&gt; means that a time series has a constant mean and constant variance over time. Althouth not particularly imporant for the estimation of parameters of econometric models these features are essential for the calculation of reliable test statistics and, hence, can have a significant impact on model selection.&lt;/p&gt;&#xA;&lt;p&gt;To illustrate this concept, let’s look at quarterly data on disposable income in billion DM from 1960 to 1982, which is data set E1 from Luetkepohl (2007).&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Introduction to Impulse Response Analysis of VAR Models</title>
      <link>https://www.r-econometrics.com/timeseries/irf/</link>
      <pubDate>Sat, 21 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/timeseries/irf/</guid>
      <description>&lt;p&gt;Impulse response analysis is an important step in econometric analyes, which employ &lt;a href=&#34;https://www.r-econometrics.com/timeseries/varintro&#34; target=&#34;_blank&#34;&gt;vector autoregressive models&lt;/a&gt;. Their main purpose is to describe the evolution of a model’s variables in reaction to a shock in one or more variables. This feature allows to trace the transmission of a single shock within an otherwise noisy system of equations and, thus, makes them very useful tools in the assessment of economic policies. This post provides an introduction to the concept and interpretation of impulse response functions as they are commonly used in the VAR literature and provides code for their calculation in R.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to dplyr</title>
      <link>https://www.r-econometrics.com/rbasics/dplyrintro/</link>
      <pubDate>Mon, 07 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/rbasics/dplyrintro/</guid>
      <description>&lt;p&gt;The cleaning and transformation of data belong to the most time consuming parts of any economic analysis. Many graphical or statistical functions in R require specifically formatted data to work properly. Although the standard functions of R can be used to prepare your data for further analysis, some people find them a bit laborious for daily applications. Therefore, alternatives have been developed, which make data transformation in R easier and also faster. One of these alternatives is the &lt;code&gt;dplyr&lt;/code&gt; package of the &lt;a href=&#34;https://www.tidyverse.org/&#34; target=&#34;_blank&#34;&gt;tidyverse&lt;/a&gt;. It has gained great popularity among R users and being familiar with its syntax can be considered a standard skill in R.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; In the following I give an introduction to some main functions of &lt;code&gt;dplyr&lt;/code&gt;, which I also use extensively at work.&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Introduction to Vector Error Correction Models (VECMs)</title>
      <link>https://www.r-econometrics.com/timeseries/vecintro/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/timeseries/vecintro/</guid>
      <description>&lt;p&gt;One of the prerequisits for the estimation of a &lt;a href=&#34;https://www.r-econometrics.com/timeseries/varintro&#34;&gt;vector autoregressive (VAR)&lt;/a&gt; model is that the analysed time series are stationary. However, economic theory suggests that there exist equilibrium relations between economic variables in their levels, which can render these variables stationary without taking differences. This is called &lt;em&gt;cointegration&lt;/em&gt;. Since knowing the size of such relationships can improve the results of an analysis, it would be desireable to have an econometric model, which is able to capture them. So-called &lt;em&gt;vector error correction models&lt;/em&gt; (VECMs) belong to this class of models. The following text presents the basic concept of VECMs and guides through the estimation of such a model in R.&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Introduction to Bayesian VAR (BVAR) Models</title>
      <link>https://www.r-econometrics.com/timeseries/bvar/</link>
      <pubDate>Sun, 07 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/timeseries/bvar/</guid>
      <description>&lt;p&gt;Bayesian methods have significantly gained in popularity during the last decades as computers have become more powerful and new software has been developed. Their flexibility and other advantageous features have made these methods also more popular in econometrics. This post gives a brief introduction to Bayesian VAR (BVAR) models and provides the code to set up and estimate a basic model with the &lt;a href=&#34;https://cran.r-project.org/package=bvartools&#34;&gt;&lt;code&gt;bvartools&lt;/code&gt;&lt;/a&gt; package.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bayesian Error Correction Models with Priors on the Cointegration Space</title>
      <link>https://www.r-econometrics.com/timeseries/bvec/</link>
      <pubDate>Tue, 11 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/timeseries/bvec/</guid>
      <description>&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;This post provides the code to set up and estimate a basic Bayesian vector error correction (BVEC) model with the &lt;code&gt;bvartools&lt;/code&gt; package. The presented Gibbs sampler is based on the approach of Koop et al. (2010), who propose a prior on the cointegration space.&lt;/p&gt;&#xA;&lt;/div&gt;&#xA;&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Data&lt;/h2&gt;&#xA;&lt;p&gt;To illustrate the estimation process, the dataset E6 from Lütkepohl (2007) is used, which contains data on German long-term interest rates and inflation from 1972Q2 to 1998Q4.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Stochastic Search Variable Selection</title>
      <link>https://www.r-econometrics.com/timeseries/ssvs/</link>
      <pubDate>Tue, 11 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/timeseries/ssvs/</guid>
      <description>&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;A general drawback of vector autoregressive (VAR) models is that the number of estimated coefficients increases disproportionately with the number of lags. Therefore, fewer information per parameter is available for the estimation as the number of lags increases. In the Bayesian VAR literature one approach to mitigate this so-called &lt;em&gt;curse of dimensionality&lt;/em&gt; is &lt;em&gt;stochastic search variable selection&lt;/em&gt; (SSVS) as proposed by George et al. (2008). The basic idea of SSVS is to assign commonly used prior variances to parameters, which should be included in a model, and prior variances close to zero to irrelevant parameters. By that, relevant parameters are estimated in the usual way and posterior draws of irrelevant variables are close to zero so that they have no significant effect on forecasts and impulse responses. This is achieved by adding a hierarchial prior to the model, where the relevance of a variable is assessed in each step of the sampling algorithm.&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Reproduction: Timmer, M. P., Dietzenbacher, E., Los, B., Stehrer, R., &amp; De Vries, G. J. (2015). An illustrated user guide to the world input–output database: the case of global automotive production.</title>
      <link>https://www.r-econometrics.com/reproduction/2015_timmer_wiod/</link>
      <pubDate>Mon, 20 May 2019 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/2015_timmer_wiod/</guid>
      <description>&lt;p&gt;As international trade has become increasingly fragmented over the past decades the analysis of global value chains (GVC) has gained popularity in economic research. This post reproduces Timmer et al. (2015), who introduce the world input-output database (WIOD) and present basic concepts of GVC analysis.&lt;/p&gt;&#xA;&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Data&lt;/h2&gt;&#xA;&lt;p&gt;Timmer et al. (2015) use the 2013 vintage of the world input-output database (&lt;a href=&#34;http://www.wiod.org/database/wiots13&#34; target=&#34;_blank&#34;&gt;WIOD&lt;/a&gt;). The following code downloads the data from the project’s website, unzips it and loads the resulting STATA file into R using the &lt;code&gt;readstata13&lt;/code&gt; package.&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>William Shakespeare&#39;s Work in a Word Cloud</title>
      <link>https://www.r-econometrics.com/2018/12/30/william-shakespeares-work-in-a-word-cloud/</link>
      <pubDate>Sun, 30 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/2018/12/30/william-shakespeares-work-in-a-word-cloud/</guid>
      <description>&lt;p&gt;Word or tag clouds seem to be quite popular at the moment. Although their analytical power might be limited, they do serve an aesthetic purpose and, for example, could be put on the cover page of a thesis or a presentation using the content of your work or the literature you went through. This post uses text data from the Gutenberg project to give a step-by-step introduction on how to create a wordcould in R.&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Introduction to Vector Autoregression (VAR)</title>
      <link>https://www.r-econometrics.com/timeseries/varintro/</link>
      <pubDate>Fri, 31 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/timeseries/varintro/</guid>
      <description>&lt;p&gt;Since the seminal paper of Sims (1980) vector autoregressive models have become a key instrument in macroeconomic research. This post presents the basic concept of VAR analysis and guides through the estimation procedure of a simple model. When I started my undergraduate program in economics I occasionally encountered the abbreviation &lt;em&gt;VAR&lt;/em&gt; in some macro papers. I was fascinated by those waves in the boxes titled &lt;em&gt;impulse responses&lt;/em&gt; and wondered how difficult it would be to do such reseach on my own. I was motivated, but my first attempts were admittedly embarrassing. It took me quite a long time to figure out which kind of data can be analysed, how to estimate a VAR model and how to obtain meaningful impulse responses. Today, I think that there is nothing fancy about VAR models at all once you keep in mind some points.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data Visualisation in R Using ggplot2</title>
      <link>https://www.r-econometrics.com/rbasics/ggplotintro/</link>
      <pubDate>Sun, 04 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/rbasics/ggplotintro/</guid>
      <description>&lt;p&gt;A major challenge in data analysis is to summarise and present data with informative graphs. The &lt;code&gt;ggplot2&lt;/code&gt; package was specifically designed to help with this task. Since it is a very powerful and well documented package&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;, this introduction will only focus on its basic syntax, so that the user gets a better understanding of how to read the supporting material on the internet.&lt;/p&gt;&#xA;&lt;p&gt;ggplot graphs are built with some kind of blocks, which usually start with the function &lt;code&gt;ggplot&lt;/code&gt;. Its first argument contains the data object and the second argument is a further function called &lt;code&gt;aes&lt;/code&gt;.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; It controls, which columns of the data frame are used for the axes, colours, shapes of the data points and further features of the graph. The remaining blocks are separated by plus &lt;code&gt;+&lt;/code&gt; signs and – if not specified otherwise – take the information from the first block and add a certain aspect to the graph, for example additional lines or data points. To understand what this all means, let us look at some basic examples.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Reproduction: Sheperd, B. (2016). The gravity model of international trade: A user guide.</title>
      <link>https://www.r-econometrics.com/reproduction/2016_sheperd_gravity/</link>
      <pubDate>Tue, 30 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://www.r-econometrics.com/reproduction/2016_sheperd_gravity/</guid>
      <description>&lt;p&gt;The updated paper and dataset can be downloaded from &lt;a href=&#34;http://www.unescap.org/resources/gravity-model-international-trade-user-guide-updated-version&#34; target=&#34;_blank&#34;&gt;UNESCAP&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;div id=&#34;load-libraries-and-read-data&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Load libraries and read data&lt;/h2&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(AER)&#xA;library(dplyr)&#xA;library(foreign)&#xA;library(ggplot2)&#xA;library(lmtest)&#xA;library(multiwayvcov)&#xA;library(sampleSelection)&#xA;&#xA;data &amp;lt;- read.dta(&amp;quot;servicesdataset_2016.dta&amp;quot;)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div id=&#34;correlations&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Correlations&lt;/h2&gt;&#xA;&lt;p&gt;Table 1&lt;/p&gt;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- data %&amp;gt;% &#xA;  mutate(ln_trade = log(trade),&#xA;         ln_distance = log(dist),&#xA;         ln_gdp_exp = log(gdp_exp),&#xA;         ln_gdp_imp = log(gdp_imp))&#xA;&#xA;cor.data &amp;lt;- data %&amp;gt;% &#xA;  filter(sector == &amp;quot;SER&amp;quot;) %&amp;gt;% &#xA;  select(ln_trade, ln_gdp_exp, ln_gdp_imp, ln_distance) %&amp;gt;%&#xA;  na.omit %&amp;gt;% &#xA;  filter(ln_trade &amp;gt; -Inf)&#xA;&#xA;round(cor(cor.data), 4)&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;pre&gt;&lt;code&gt;##             ln_trade ln_gdp_exp ln_gdp_imp ln_distance&#xA;## ln_trade      1.0000     0.3643     0.3731     -0.2648&#xA;## ln_gdp_exp    0.3643     1.0000    -0.3103      0.0518&#xA;## ln_gdp_imp    0.3731    -0.3103     1.0000      0.0431&#xA;## ln_distance  -0.2648     0.0518     0.0431      1.0000&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;div id=&#34;graphics&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Graphics&lt;/h2&gt;&#xA;&lt;p&gt;Prepare data&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
